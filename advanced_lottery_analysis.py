#!/usr/bin/env python3
"""
é€²éšå½©ç¥¨åˆ†æç³»çµ±
åŒ…å«æ™‚é–“åŠ æ¬Šåˆ†æã€æœªé–‹å‡ºçµ„åˆæª¢æŸ¥ã€æ­·å²æ¿è·¯ç›¸ä¼¼æ€§é æ¸¬
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from itertools import combinations
from collections import defaultdict, Counter
import math
import json
from pathlib import Path

class AdvancedLotteryAnalyzer:
    def __init__(self, excel_file="lottery_hist.xlsx"):
        """åˆå§‹åŒ–é€²éšåˆ†æå™¨"""
        self.excel_file = excel_file
        self.df = None
        self.load_data()
    
    def load_data(self):
        """è¼‰å…¥æ­·å²è³‡æ–™"""
        try:
            self.df = pd.read_excel(self.excel_file, engine='openpyxl')
            self.df['æ—¥æœŸ'] = pd.to_datetime(self.df['æ—¥æœŸ'])
            self.df = self.df.sort_values('æ—¥æœŸ').reset_index(drop=True)
            print(f"âœ… è¼‰å…¥ {len(self.df)} ç­†æ­·å²è¨˜éŒ„")
            print(f"ğŸ“… æ—¥æœŸç¯„åœ: {self.df['æ—¥æœŸ'].min().date()} ~ {self.df['æ—¥æœŸ'].max().date()}")
        except Exception as e:
            print(f"âŒ è¼‰å…¥è³‡æ–™å¤±æ•—: {e}")
            self.df = None
    
    def compute_weighted_frequency(self, decay_factor=0.95, recent_days=365):
        """
        è¨ˆç®—æ™‚é–“åŠ æ¬Šçš„è™Ÿç¢¼é »ç‡
        
        Args:
            decay_factor: è¡°æ¸›ä¿‚æ•¸ (0-1)ï¼Œè¶Šæ¥è¿‘1è¡°æ¸›è¶Šæ…¢
            recent_days: åªè€ƒæ…®æœ€è¿‘Nå¤©çš„è¨˜éŒ„
        
        Returns:
            dict: {è™Ÿç¢¼: åŠ æ¬Šé »ç‡}
        """
        if self.df is None:
            return {}
        
        print(f"\nâš–ï¸ è¨ˆç®—æ™‚é–“åŠ æ¬Šé »ç‡ (è¡°æ¸›ä¿‚æ•¸: {decay_factor})")
        
        # åªå–æœ€è¿‘çš„è¨˜éŒ„
        cutoff_date = datetime.now() - timedelta(days=recent_days)
        recent_df = self.df[self.df['æ—¥æœŸ'] >= cutoff_date].copy()
        
        if len(recent_df) == 0:
            print("âš ï¸ æ²’æœ‰è¶³å¤ çš„è¿‘æœŸè¨˜éŒ„")
            return {}
        
        print(f"ğŸ“Š åˆ†ææœ€è¿‘ {len(recent_df)} ç­†è¨˜éŒ„ (è¿‘ {recent_days} å¤©)")
        
        # è¨ˆç®—æ¯ç­†è¨˜éŒ„è·ä»Šçš„å¤©æ•¸
        today = datetime.now()
        recent_df['days_ago'] = (today - recent_df['æ—¥æœŸ']).dt.days
        
        # è¨ˆç®—åŠ æ¬Šé »ç‡
        weighted_freq = defaultdict(float)
        
        for _, row in recent_df.iterrows():
            # è¨ˆç®—æ¬Šé‡ï¼šè¶Šè¿‘æœŸæ¬Šé‡è¶Šé«˜
            weight = decay_factor ** row['days_ago']
            
            # ç´¯åŠ æ¯å€‹è™Ÿç¢¼çš„åŠ æ¬Šé »ç‡
            for col in ['è™Ÿç¢¼1', 'è™Ÿç¢¼2', 'è™Ÿç¢¼3', 'è™Ÿç¢¼4', 'è™Ÿç¢¼5']:
                if pd.notna(row[col]):
                    number = int(row[col])
                    weighted_freq[number] += weight
        
        # æ­£è¦åŒ–é »ç‡
        total_weight = sum(weighted_freq.values())
        if total_weight > 0:
            for num in weighted_freq:
                weighted_freq[num] = weighted_freq[num] / total_weight
        
        # æ’åºä¸¦é¡¯ç¤ºçµæœ
        sorted_freq = sorted(weighted_freq.items(), key=lambda x: x[1], reverse=True)
        
        print("ğŸ”¥ åŠ æ¬Šç†±è™Ÿ (å‰10):")
        for i, (num, freq) in enumerate(sorted_freq[:10]):
            print(f"   {i+1:2d}. è™Ÿç¢¼ {num:2d}: {freq:.4f}")
        
        print("â„ï¸ åŠ æ¬Šå†·è™Ÿ (å¾Œ10):")
        for i, (num, freq) in enumerate(sorted_freq[-10:]):
            print(f"   {i+1:2d}. è™Ÿç¢¼ {num:2d}: {freq:.4f}")
        
        return dict(weighted_freq)
    
    def find_never_drawn_combinations(self, combo_size=5, sample_size=1000):
        """
        æ‰¾å‡ºå¾æœªé–‹å‡ºçš„è™Ÿç¢¼çµ„åˆ
        
        Args:
            combo_size: çµ„åˆå¤§å° (é è¨­5å€‹è™Ÿç¢¼)
            sample_size: æŠ½æ¨£æª¢æŸ¥çš„çµ„åˆæ•¸é‡
        
        Returns:
            list: å¾æœªé–‹å‡ºçš„çµ„åˆåˆ—è¡¨
        """
        if self.df is None:
            return []
        
        print(f"\nğŸ” åˆ†æå¾æœªé–‹å‡ºçš„ {combo_size} è™Ÿçµ„åˆ...")
        
        # æå–æ‰€æœ‰æ­·å²é–‹ççµ„åˆ
        historical_combinations = set()
        
        for _, row in self.df.iterrows():
            numbers = []
            for col in ['è™Ÿç¢¼1', 'è™Ÿç¢¼2', 'è™Ÿç¢¼3', 'è™Ÿç¢¼4', 'è™Ÿç¢¼5']:
                if pd.notna(row[col]):
                    numbers.append(int(row[col]))
            
            if len(numbers) == 5:
                # è½‰æ›ç‚ºæ’åºçš„ tuple
                combo = tuple(sorted(numbers))
                historical_combinations.add(combo)
        
        print(f"ğŸ“Š æ­·å²é–‹å‡ºçµ„åˆæ•¸: {len(historical_combinations):,}")
        
        # è¨ˆç®—ç¸½å¯èƒ½çµ„åˆæ•¸
        total_combinations = len(list(combinations(range(1, 40), combo_size)))
        never_drawn_count = total_combinations - len(historical_combinations)
        
        print(f"ğŸ² ç¸½å¯èƒ½çµ„åˆæ•¸: {total_combinations:,}")
        print(f"ğŸ’ å¾æœªé–‹å‡ºçµ„åˆæ•¸: {never_drawn_count:,} ({never_drawn_count/total_combinations*100:.2f}%)")
        
        # éš¨æ©ŸæŠ½æ¨£æª¢æŸ¥å¾æœªé–‹å‡ºçš„çµ„åˆ
        never_drawn_samples = []
        checked_count = 0
        
        print(f"\nğŸ¯ éš¨æ©ŸæŠ½æ¨£æª¢æŸ¥ {sample_size} å€‹çµ„åˆ...")
        
        # ç”Ÿæˆéš¨æ©Ÿçµ„åˆä¸¦æª¢æŸ¥
        while len(never_drawn_samples) < sample_size and checked_count < sample_size * 10:
            # éš¨æ©Ÿç”Ÿæˆä¸€å€‹çµ„åˆ
            random_combo = tuple(sorted(np.random.choice(range(1, 40), combo_size, replace=False)))
            checked_count += 1
            
            if random_combo not in historical_combinations:
                never_drawn_samples.append(random_combo)
        
        print(f"âœ… æ‰¾åˆ° {len(never_drawn_samples)} å€‹å¾æœªé–‹å‡ºçš„çµ„åˆ")
        
        # é¡¯ç¤ºå‰10å€‹
        print("\nğŸ’ å¾æœªé–‹å‡ºçµ„åˆç¯„ä¾‹ (å‰10å€‹):")
        for i, combo in enumerate(never_drawn_samples[:10]):
            print(f"   {i+1:2d}. {list(combo)}")
        
        return never_drawn_samples
    
    def analyze_recent_patterns(self, pattern_length=5):
        """
        åˆ†ææœ€è¿‘çš„é–‹çæ¨¡å¼
        
        Args:
            pattern_length: æ¨¡å¼é•·åº¦ï¼ˆåˆ†ææœ€è¿‘NæœŸï¼‰
        
        Returns:
            dict: æœ€è¿‘æ¨¡å¼çš„ç‰¹å¾µ
        """
        if self.df is None or len(self.df) < pattern_length:
            return {}
        
        print(f"\nğŸ“ˆ åˆ†ææœ€è¿‘ {pattern_length} æœŸçš„é–‹çæ¨¡å¼...")
        
        # å–æœ€è¿‘çš„è¨˜éŒ„
        recent_records = self.df.tail(pattern_length)
        
        pattern_features = {
            'dates': [],
            'numbers_sequence': [],
            'sum_trend': [],
            'even_odd_ratio': [],
            'high_low_ratio': [],
            'consecutive_pairs': [],
            'number_gaps': []
        }
        
        for _, row in recent_records.iterrows():
            numbers = []
            for col in ['è™Ÿç¢¼1', 'è™Ÿç¢¼2', 'è™Ÿç¢¼3', 'è™Ÿç¢¼4', 'è™Ÿç¢¼5']:
                if pd.notna(row[col]):
                    numbers.append(int(row[col]))
            
            if len(numbers) == 5:
                numbers = sorted(numbers)
                pattern_features['dates'].append(row['æ—¥æœŸ'])
                pattern_features['numbers_sequence'].append(numbers)
                
                # è¨ˆç®—å„ç¨®ç‰¹å¾µ
                num_sum = sum(numbers)
                pattern_features['sum_trend'].append(num_sum)
                
                # å¥‡å¶æ¯”ä¾‹
                even_count = sum(1 for n in numbers if n % 2 == 0)
                pattern_features['even_odd_ratio'].append(even_count / 5)
                
                # é«˜ä½æ¯”ä¾‹ (20ä»¥ä¸Šç‚ºé«˜)
                high_count = sum(1 for n in numbers if n > 20)
                pattern_features['high_low_ratio'].append(high_count / 5)
                
                # é€£çºŒè™Ÿç¢¼å°
                consecutive = sum(1 for i in range(len(numbers)-1) if numbers[i+1] - numbers[i] == 1)
                pattern_features['consecutive_pairs'].append(consecutive)
                
                # è™Ÿç¢¼é–“è·
                gaps = [numbers[i+1] - numbers[i] for i in range(len(numbers)-1)]
                pattern_features['number_gaps'].append(gaps)
        
        # é¡¯ç¤ºæ¨¡å¼åˆ†æ
        print("\nğŸ“‹ æœ€è¿‘æ¨¡å¼ç‰¹å¾µ:")
        for i, (date, numbers) in enumerate(zip(pattern_features['dates'], pattern_features['numbers_sequence'])):
            print(f"   {date.date()}: {numbers} (å’Œ:{pattern_features['sum_trend'][i]})")
        
        # è¨ˆç®—è¶¨å‹¢
        if len(pattern_features['sum_trend']) >= 3:
            recent_avg = np.mean(pattern_features['sum_trend'][-3:])
            overall_avg = np.mean(pattern_features['sum_trend'])
            print(f"\nğŸ“Š æ•¸å­—å’Œè¶¨å‹¢:")
            print(f"   æœ€è¿‘3æœŸå¹³å‡: {recent_avg:.1f}")
            print(f"   æ•´é«”å¹³å‡: {overall_avg:.1f}")
            print(f"   è¶¨å‹¢: {'ğŸ“ˆ åé«˜' if recent_avg > overall_avg else 'ğŸ“‰ åä½'}")
        
        return pattern_features
    
    def find_similar_historical_patterns(self, current_pattern, similarity_threshold=0.8):
        """
        åœ¨æ­·å²ä¸­å°‹æ‰¾ç›¸ä¼¼çš„æ¿è·¯æ¨¡å¼
        
        Args:
            current_pattern: ç•¶å‰æ¨¡å¼ç‰¹å¾µ
            similarity_threshold: ç›¸ä¼¼åº¦é–¾å€¼
        
        Returns:
            list: ç›¸ä¼¼çš„æ­·å²æ¨¡å¼åŠå…¶å¾ŒçºŒé–‹ç
        """
        if self.df is None or not current_pattern:
            return []
        
        print(f"\nğŸ§  å°‹æ‰¾æ­·å²ç›¸ä¼¼æ¿è·¯ (ç›¸ä¼¼åº¦é–¾å€¼: {similarity_threshold})")
        
        pattern_length = len(current_pattern['numbers_sequence'])
        if pattern_length == 0:
            return []
        
        similar_patterns = []
        
        # åœ¨æ­·å²ä¸­æ»‘å‹•çª—å£å°‹æ‰¾ç›¸ä¼¼æ¨¡å¼
        for i in range(len(self.df) - pattern_length):
            # æå–æ­·å²æ¨¡å¼
            historical_pattern = self.extract_pattern_features(i, pattern_length)
            
            if historical_pattern:
                # è¨ˆç®—ç›¸ä¼¼åº¦
                similarity = self.calculate_pattern_similarity(current_pattern, historical_pattern)
                
                if similarity >= similarity_threshold:
                    # æ‰¾åˆ°ç›¸ä¼¼æ¨¡å¼ï¼Œè¨˜éŒ„å…¶å¾ŒçºŒé–‹ç
                    next_index = i + pattern_length
                    if next_index < len(self.df):
                        next_record = self.df.iloc[next_index]
                        next_numbers = []
                        for col in ['è™Ÿç¢¼1', 'è™Ÿç¢¼2', 'è™Ÿç¢¼3', 'è™Ÿç¢¼4', 'è™Ÿç¢¼5']:
                            if pd.notna(next_record[col]):
                                next_numbers.append(int(next_record[col]))
                        
                        if len(next_numbers) == 5:
                            similar_patterns.append({
                                'start_date': self.df.iloc[i]['æ—¥æœŸ'],
                                'end_date': self.df.iloc[i + pattern_length - 1]['æ—¥æœŸ'],
                                'similarity': similarity,
                                'pattern': historical_pattern['numbers_sequence'],
                                'next_draw': sorted(next_numbers),
                                'next_date': next_record['æ—¥æœŸ']
                            })
        
        # æ’åºç›¸ä¼¼æ¨¡å¼
        similar_patterns.sort(key=lambda x: x['similarity'], reverse=True)
        
        print(f"ğŸ” æ‰¾åˆ° {len(similar_patterns)} å€‹ç›¸ä¼¼çš„æ­·å²æ¨¡å¼")
        
        # é¡¯ç¤ºå‰5å€‹æœ€ç›¸ä¼¼çš„æ¨¡å¼
        print("\nğŸ¯ æœ€ç›¸ä¼¼çš„æ­·å²æ¨¡å¼:")
        for i, pattern in enumerate(similar_patterns[:5]):
            print(f"   {i+1}. ç›¸ä¼¼åº¦: {pattern['similarity']:.3f}")
            print(f"      æ™‚æœŸ: {pattern['start_date'].date()} ~ {pattern['end_date'].date()}")
            print(f"      å¾ŒçºŒé–‹ç: {pattern['next_draw']} ({pattern['next_date'].date()})")
        
        return similar_patterns
    
    def extract_pattern_features(self, start_index, length):
        """æå–æŒ‡å®šä½ç½®çš„æ¨¡å¼ç‰¹å¾µ"""
        try:
            pattern_records = self.df.iloc[start_index:start_index + length]
            
            features = {
                'numbers_sequence': [],
                'sum_trend': [],
                'even_odd_ratio': [],
                'high_low_ratio': []
            }
            
            for _, row in pattern_records.iterrows():
                numbers = []
                for col in ['è™Ÿç¢¼1', 'è™Ÿç¢¼2', 'è™Ÿç¢¼3', 'è™Ÿç¢¼4', 'è™Ÿç¢¼5']:
                    if pd.notna(row[col]):
                        numbers.append(int(row[col]))
                
                if len(numbers) == 5:
                    numbers = sorted(numbers)
                    features['numbers_sequence'].append(numbers)
                    features['sum_trend'].append(sum(numbers))
                    
                    even_count = sum(1 for n in numbers if n % 2 == 0)
                    features['even_odd_ratio'].append(even_count / 5)
                    
                    high_count = sum(1 for n in numbers if n > 20)
                    features['high_low_ratio'].append(high_count / 5)
            
            return features if len(features['numbers_sequence']) == length else None
            
        except Exception as e:
            return None
    
    def calculate_pattern_similarity(self, pattern1, pattern2):
        """è¨ˆç®—å…©å€‹æ¨¡å¼çš„ç›¸ä¼¼åº¦"""
        try:
            # æ¯”è¼ƒæ•¸å­—å’Œè¶¨å‹¢
            sum_similarity = 1 - abs(np.mean(pattern1['sum_trend']) - np.mean(pattern2['sum_trend'])) / 200
            
            # æ¯”è¼ƒå¥‡å¶æ¯”ä¾‹è¶¨å‹¢
            even_odd_similarity = 1 - abs(np.mean(pattern1['even_odd_ratio']) - np.mean(pattern2['even_odd_ratio']))
            
            # æ¯”è¼ƒé«˜ä½æ¯”ä¾‹è¶¨å‹¢
            high_low_similarity = 1 - abs(np.mean(pattern1['high_low_ratio']) - np.mean(pattern2['high_low_ratio']))
            
            # ç¶œåˆç›¸ä¼¼åº¦
            total_similarity = (sum_similarity + even_odd_similarity + high_low_similarity) / 3
            
            return max(0, total_similarity)
            
        except Exception as e:
            return 0
    
    def weighted_smart_prediction(self, n_predictions=9, decay_factor=0.95):
        """
        åŸºæ–¼æ™‚é–“åŠ æ¬Šçš„æ™ºèƒ½é¸è™Ÿ
        
        Args:
            n_predictions: é æ¸¬è™Ÿç¢¼æ•¸é‡
            decay_factor: æ™‚é–“è¡°æ¸›ä¿‚æ•¸
        
        Returns:
            list: é æ¸¬è™Ÿç¢¼
        """
        print(f"\nğŸ¯ æ™‚é–“åŠ æ¬Šæ™ºèƒ½é¸è™Ÿ (é æ¸¬ {n_predictions} å€‹è™Ÿç¢¼)")
        
        # è¨ˆç®—åŠ æ¬Šé »ç‡
        weighted_freq = self.compute_weighted_frequency(decay_factor)
        
        if not weighted_freq:
            print("âŒ ç„¡æ³•è¨ˆç®—åŠ æ¬Šé »ç‡")
            return []
        
        # è½‰æ›ç‚ºå¯ç”¨æ–¼é¸è™Ÿçš„æ¬Šé‡
        numbers = list(range(1, 40))
        weights = [weighted_freq.get(num, 0.001) for num in numbers]  # çµ¦æœªå‡ºç¾è™Ÿç¢¼å°æ¬Šé‡
        
        # åŠ å…¥ä¸€äº›éš¨æ©Ÿæ€§ï¼Œé¿å…éåº¦ä¾è³´æ­·å²
        randomness_factor = 0.3
        for i in range(len(weights)):
            weights[i] = weights[i] * (1 - randomness_factor) + np.random.random() * randomness_factor
        
        # æ­£è¦åŒ–æ¬Šé‡
        weights = np.array(weights)
        weights = weights / weights.sum()
        
        # æ ¹æ“šæ¬Šé‡é¸è™Ÿ
        selected_numbers = np.random.choice(numbers, size=n_predictions, replace=False, p=weights)
        result = sorted(selected_numbers.tolist())
        
        print(f"âœ… åŠ æ¬Šæ™ºèƒ½é¸è™Ÿçµæœ: {result}")
        
        return result
    
    def pattern_based_prediction(self, pattern_length=5):
        """
        åŸºæ–¼æ­·å²æ¿è·¯ç›¸ä¼¼æ€§çš„é æ¸¬
        
        Args:
            pattern_length: æ¨¡å¼é•·åº¦
        
        Returns:
            dict: é æ¸¬çµæœå’Œä¿¡å¿ƒåº¦
        """
        print(f"\nğŸ§  åŸºæ–¼æ¿è·¯ç›¸ä¼¼æ€§é æ¸¬ (æ¨¡å¼é•·åº¦: {pattern_length})")
        
        # åˆ†ææœ€è¿‘æ¨¡å¼
        current_pattern = self.analyze_recent_patterns(pattern_length)
        
        if not current_pattern:
            print("âŒ ç„¡æ³•åˆ†æç•¶å‰æ¨¡å¼")
            return {}
        
        # å°‹æ‰¾ç›¸ä¼¼æ­·å²æ¨¡å¼
        similar_patterns = self.find_similar_historical_patterns(current_pattern)
        
        if not similar_patterns:
            print("âŒ æ²’æœ‰æ‰¾åˆ°ç›¸ä¼¼çš„æ­·å²æ¨¡å¼")
            return {}
        
        # çµ±è¨ˆç›¸ä¼¼æ¨¡å¼çš„å¾ŒçºŒé–‹ç
        next_number_freq = defaultdict(int)
        total_patterns = len(similar_patterns)
        
        for pattern in similar_patterns:
            for number in pattern['next_draw']:
                # æ ¹æ“šç›¸ä¼¼åº¦åŠ æ¬Š
                weight = pattern['similarity']
                next_number_freq[number] += weight
        
        # æ­£è¦åŒ–ä¸¦æ’åº
        total_weight = sum(next_number_freq.values())
        if total_weight > 0:
            for num in next_number_freq:
                next_number_freq[num] = next_number_freq[num] / total_weight
        
        sorted_predictions = sorted(next_number_freq.items(), key=lambda x: x[1], reverse=True)
        
        # é¸æ“‡å‰9å€‹æœ€æœ‰å¯èƒ½çš„è™Ÿç¢¼
        predicted_numbers = [num for num, freq in sorted_predictions[:9]]
        
        # è¨ˆç®—æ•´é«”ä¿¡å¿ƒåº¦
        confidence = np.mean([p['similarity'] for p in similar_patterns[:5]])
        
        print(f"\nğŸ¯ æ¿è·¯é æ¸¬çµæœ:")
        print(f"   é æ¸¬è™Ÿç¢¼: {sorted(predicted_numbers)}")
        print(f"   ä¿¡å¿ƒåº¦: {confidence:.3f}")
        print(f"   åŸºæ–¼ {total_patterns} å€‹ç›¸ä¼¼æ­·å²æ¨¡å¼")
        
        return {
            'predicted_numbers': sorted(predicted_numbers),
            'confidence': confidence,
            'similar_patterns_count': total_patterns,
            'top_probabilities': sorted_predictions[:15]
        }
    
    def comprehensive_analysis(self):
        """ç¶œåˆåˆ†æå ±å‘Š"""
        print("\n" + "="*60)
        print("ğŸ² 539 å½©ç¥¨é€²éšåˆ†æå ±å‘Š")
        print("="*60)
        
        if self.df is None:
            print("âŒ ç„¡æ³•è¼‰å…¥æ­·å²è³‡æ–™")
            return
        
        # 1. æ™‚é–“åŠ æ¬Šåˆ†æ
        weighted_prediction = self.weighted_smart_prediction()
        
        # 2. å¾æœªé–‹å‡ºçµ„åˆåˆ†æ
        never_drawn = self.find_never_drawn_combinations(sample_size=500)
        
        # 3. æ¿è·¯ç›¸ä¼¼æ€§é æ¸¬
        pattern_prediction = self.pattern_based_prediction()
        
        # 4. ç¶œåˆå»ºè­°
        print("\n" + "="*60)
        print("ğŸ¯ ç¶œåˆé æ¸¬å»ºè­°")
        print("="*60)
        
        print(f"âš–ï¸ æ™‚é–“åŠ æ¬Šé¸è™Ÿ: {weighted_prediction}")
        
        if pattern_prediction:
            print(f"ğŸ§  æ¿è·¯ç›¸ä¼¼é æ¸¬: {pattern_prediction['predicted_numbers']}")
            print(f"   ä¿¡å¿ƒåº¦: {pattern_prediction['confidence']:.3f}")
        
        if never_drawn:
            # å¾æœªé–‹å‡ºçµ„åˆä¸­éš¨æ©Ÿé¸ä¸€å€‹
            random_never_drawn = never_drawn[np.random.randint(0, min(len(never_drawn), 10))]
            print(f"ğŸ’ å¾æœªé–‹å‡ºçµ„åˆ: {list(random_never_drawn)}")
        
        # ç”Ÿæˆæœ€çµ‚å»ºè­°
        final_recommendation = self.generate_final_recommendation(
            weighted_prediction, 
            pattern_prediction.get('predicted_numbers', []),
            never_drawn
        )
        
        print(f"\nğŸ† æœ€çµ‚å»ºè­°è™Ÿç¢¼: {final_recommendation}")
        
        return {
            'weighted_prediction': weighted_prediction,
            'pattern_prediction': pattern_prediction,
            'never_drawn_samples': never_drawn[:10],
            'final_recommendation': final_recommendation
        }
    
    def generate_final_recommendation(self, weighted_nums, pattern_nums, never_drawn):
        """ç”Ÿæˆæœ€çµ‚å»ºè­°è™Ÿç¢¼"""
        # çµåˆå„ç¨®ç­–ç•¥
        all_candidates = set(weighted_nums + pattern_nums)
        
        # å¦‚æœå€™é¸è™Ÿç¢¼ä¸è¶³ï¼Œå¾æœªé–‹å‡ºçµ„åˆä¸­è£œå……
        if len(all_candidates) < 9 and never_drawn:
            random_never = never_drawn[0]  # å–ç¬¬ä¸€å€‹å¾æœªé–‹å‡ºçš„çµ„åˆ
            all_candidates.update(random_never)
        
        # å¦‚æœé‚„æ˜¯ä¸è¶³ï¼Œéš¨æ©Ÿè£œå……
        if len(all_candidates) < 9:
            remaining = [i for i in range(1, 40) if i not in all_candidates]
            all_candidates.update(np.random.choice(remaining, 9 - len(all_candidates), replace=False))
        
        # å–å‰9å€‹
        final_nums = sorted(list(all_candidates)[:9])
        
        return final_nums

def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    print("ğŸš€ é€²éšå½©ç¥¨åˆ†æç³»çµ±å•Ÿå‹•")
    
    analyzer = AdvancedLotteryAnalyzer()
    
    if analyzer.df is None:
        print("âŒ ç„¡æ³•è¼‰å…¥æ­·å²è³‡æ–™")
        return
    
    # åŸ·è¡Œç¶œåˆåˆ†æ
    results = analyzer.comprehensive_analysis()
    
    # ä¿å­˜åˆ†æçµæœ
    if results:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"advanced_analysis_{timestamp}.json"
        
        # è½‰æ›è³‡æ–™é¡å‹ä»¥ä¾¿ JSON åºåˆ—åŒ–
        def convert_for_json(obj):
            if isinstance(obj, (np.integer, np.int64)):
                return int(obj)
            elif isinstance(obj, (np.floating, np.float64)):
                return float(obj)
            elif isinstance(obj, list):
                return [convert_for_json(item) for item in obj]
            elif isinstance(obj, dict):
                return {k: convert_for_json(v) for k, v in obj.items()}
            else:
                return obj
        
        json_results = convert_for_json(results)
        
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(json_results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ åˆ†æçµæœå·²ä¿å­˜è‡³: {results_file}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜åˆ†æçµæœå¤±æ•—: {e}")

if __name__ == "__main__":
    main()
