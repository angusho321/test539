#!/usr/bin/env python3
"""
åŠ å·Fantasy 5æ¯æ—¥é–‹ççˆ¬èŸ²
å°ˆé–€ç”¨æ–¼ç²å–ç•¶æ—¥æœ€æ–°çš„é–‹ççµæœ
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime, timedelta
import re
import time
import logging
import pytz

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Fantasy5DailyCrawler:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        })
        
        # åŠ å·æ™‚å€
        self.ca_timezone = pytz.timezone('America/Los_Angeles')
        self.tw_timezone = pytz.timezone('Asia/Taipei')
        
    def get_today_ca_date(self):
        """å–å¾—åŠ å·ä»Šå¤©çš„æ—¥æœŸ"""
        ca_now = datetime.now(self.ca_timezone)
        return ca_now.date()
    
    def get_today_tw_date(self):
        """å–å¾—å°ç£ä»Šå¤©çš„æ—¥æœŸ"""
        tw_now = datetime.now(self.tw_timezone)
        return tw_now.date()
    
    def crawl_daily_results(self):
        """çˆ¬å–ç•¶æ—¥é–‹ççµæœ"""
        logger.info("ğŸ¯ é–‹å§‹çˆ¬å–ç•¶æ—¥åŠ å·Fantasy 5é–‹ççµæœ...")
        
        # å–å¾—ä»Šå¤©çš„æ—¥æœŸ
        today_ca = self.get_today_ca_date()
        today_tw = self.get_today_tw_date()
        
        logger.info(f"ğŸ“… åŠ å·ä»Šå¤©: {today_ca}")
        logger.info(f"ğŸ“… å°ç£ä»Šå¤©: {today_tw}")
        
        # å˜—è©¦å¤šå€‹æ•¸æ“šæº
        data_sources = [
            {
                'name': 'åŠ å·å½©ç¥¨å®˜æ–¹ç¶²ç«™',
                'url': 'https://www.calottery.com/fantasy-5',
                'method': 'official'
            },
            {
                'name': 'LotteryUSA',
                'url': 'https://www.lotteryusa.com/california/fantasy-5/',
                'method': 'lotteryusa'
            },
            {
                'name': 'å°ç£å½©åˆ¸ç¶²',
                'url': 'https://twlottery.in/en/lotteryCA5',
                'method': 'taiwan'
            }
        ]
        
        for source in data_sources:
            try:
                logger.info(f"ğŸ” å˜—è©¦æ•¸æ“šæº: {source['name']}")
                response = self.session.get(source['url'], timeout=30)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                results = self.parse_daily_results(soup, source['method'], today_ca)
                
                if results:
                    logger.info(f"âœ… å¾ {source['name']} æˆåŠŸç²å– {len(results)} ç­†ç•¶æ—¥é–‹ççµæœ")
                    return results
                else:
                    logger.warning(f"âš ï¸ {source['name']} æœªæ‰¾åˆ°ç•¶æ—¥é–‹ççµæœ")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ {source['name']} çˆ¬å–å¤±æ•—: {e}")
                continue
        
        logger.error("âŒ æ‰€æœ‰æ•¸æ“šæºéƒ½ç„¡æ³•ç²å–ç•¶æ—¥é–‹ççµæœ")
        return []
    
    def parse_daily_results(self, soup, method, target_date):
        """è§£æç•¶æ—¥é–‹ççµæœ"""
        results = []
        
        if method == 'official':
            results = self.parse_official_daily(soup, target_date)
        elif method == 'lotteryusa':
            results = self.parse_lotteryusa_daily(soup, target_date)
        elif method == 'taiwan':
            results = self.parse_taiwan_daily(soup, target_date)
        
        return results
    
    def parse_official_daily(self, soup, target_date):
        """è§£æåŠ å·å½©ç¥¨å®˜æ–¹ç¶²ç«™çš„ç•¶æ—¥çµæœ"""
        results = []
        
        # å°‹æ‰¾æœ€æ–°çš„é–‹ççµæœ
        result_containers = soup.find_all(['div', 'section'], class_=re.compile(r'result|draw|winning|number|game', re.I))
        
        for container in result_containers:
            # æª¢æŸ¥æ˜¯å¦åŒ…å«ä»Šå¤©çš„æ—¥æœŸ
            container_text = container.get_text()
            if str(target_date) in container_text or target_date.strftime('%m/%d/%Y') in container_text:
                # æå–è™Ÿç¢¼
                numbers = self.extract_numbers_from_text(container_text)
                
                if len(numbers) >= 5:
                    results.append({
                        'date': target_date,
                        'numbers': sorted(numbers[:5])
                    })
                    logger.info(f"âœ… å®˜æ–¹ç¶²ç«™æ‰¾åˆ°ç•¶æ—¥çµæœ: {target_date} -> {sorted(numbers[:5])}")
                    break
        
        return results
    
    def parse_lotteryusa_daily(self, soup, target_date):
        """è§£æLotteryUSAçš„ç•¶æ—¥çµæœ"""
        results = []
        
        # å°‹æ‰¾çµæœè¡¨æ ¼
        tables = soup.find_all('table')
        
        for table in tables:
            rows = table.find_all('tr')
            
            for row in rows:
                row_text = row.get_text()
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«ä»Šå¤©çš„æ—¥æœŸ
                if str(target_date) in row_text or target_date.strftime('%m/%d/%Y') in row_text:
                    numbers = self.extract_numbers_from_text(row_text)
                    
                    if len(numbers) >= 5:
                        results.append({
                            'date': target_date,
                            'numbers': sorted(numbers[:5])
                        })
                        logger.info(f"âœ… LotteryUSAæ‰¾åˆ°ç•¶æ—¥çµæœ: {target_date} -> {sorted(numbers[:5])}")
                        break
        
        return results
    
    def parse_taiwan_daily(self, soup, target_date):
        """è§£æå°ç£å½©åˆ¸ç¶²çš„ç•¶æ—¥çµæœ"""
        results = []
        
        # å°‹æ‰¾çµæœè¡¨æ ¼
        tables = soup.find_all('table')
        
        for table in tables:
            rows = table.find_all('tr')
            
            for row in rows:
                row_text = row.get_text()
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«ä»Šå¤©çš„æ—¥æœŸ
                if str(target_date) in row_text or target_date.strftime('%Y-%m-%d') in row_text:
                    numbers = self.extract_numbers_from_text(row_text)
                    
                    if len(numbers) >= 5:
                        results.append({
                            'date': target_date,
                            'numbers': sorted(numbers[:5])
                        })
                        logger.info(f"âœ… å°ç£å½©åˆ¸ç¶²æ‰¾åˆ°ç•¶æ—¥çµæœ: {target_date} -> {sorted(numbers[:5])}")
                        break
        
        return results
    
    def extract_numbers_from_text(self, text):
        """å¾æ–‡å­—ä¸­æå–è™Ÿç¢¼"""
        numbers = re.findall(r'\b(\d{1,2})\b', text)
        return [int(num) for num in numbers if 1 <= int(num) <= 39]
    
    def format_daily_result(self, result):
        """æ ¼å¼åŒ–ç•¶æ—¥çµæœç‚ºExcelæ ¼å¼"""
        date_obj = result['date']
        numbers = result['numbers']
        
        # ç”ŸæˆæœŸåˆ¥è™Ÿç¢¼
        year = date_obj.year % 100
        month = date_obj.month
        day = date_obj.day
        period = f"{year:02d}{month:02d}{day:02d}001"
        
        # å–å¾—ä¸­æ–‡æ˜ŸæœŸ
        weekdays = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥']
        weekday = weekdays[date_obj.weekday()]
        
        return {
            'æ—¥æœŸ': date_obj.strftime('%Y-%m-%d %H:%M:%S'),
            'æ˜ŸæœŸ': weekday,
            'è™Ÿç¢¼1': numbers[0],
            'è™Ÿç¢¼2': numbers[1],
            'è™Ÿç¢¼3': numbers[2],
            'è™Ÿç¢¼4': numbers[3],
            'è™Ÿç¢¼5': numbers[4],
            'æœŸåˆ¥': period
        }
    
    def update_history_file(self, new_result):
        """æ›´æ–°æ­·å²æª”æ¡ˆ"""
        try:
            # è®€å–ç¾æœ‰æ­·å²æª”æ¡ˆ
            if pd.io.common.file_exists('fantasy5_hist.xlsx'):
                df = pd.read_excel('fantasy5_hist.xlsx', engine='openpyxl')
                logger.info(f"ğŸ“ è®€å–ç¾æœ‰æ­·å²æª”æ¡ˆï¼ŒåŒ…å« {len(df)} ç­†è¨˜éŒ„")
            else:
                df = pd.DataFrame(columns=['æ—¥æœŸ', 'æ˜ŸæœŸ', 'è™Ÿç¢¼1', 'è™Ÿç¢¼2', 'è™Ÿç¢¼3', 'è™Ÿç¢¼4', 'è™Ÿç¢¼5', 'æœŸåˆ¥'])
                logger.info("ğŸ“ å»ºç«‹æ–°çš„æ­·å²æª”æ¡ˆ")
            
            # æ ¼å¼åŒ–æ–°çµæœ
            new_record = self.format_daily_result(new_result)
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing_dates = df['æ—¥æœŸ'].str[:10] if not df.empty else []
            new_date = new_record['æ—¥æœŸ'][:10]
            
            if new_date in existing_dates.values:
                logger.warning(f"âš ï¸ æ—¥æœŸ {new_date} çš„è¨˜éŒ„å·²å­˜åœ¨ï¼Œè·³éæ›´æ–°")
                return False
            
            # æ–°å¢è¨˜éŒ„
            new_df = pd.DataFrame([new_record])
            updated_df = pd.concat([df, new_df], ignore_index=True)
            
            # æŒ‰æ—¥æœŸæ’åº
            updated_df = updated_df.sort_values('æ—¥æœŸ')
            
            # ä¿å­˜æª”æ¡ˆ
            updated_df.to_excel('fantasy5_hist.xlsx', index=False, engine='openpyxl')
            
            logger.info(f"âœ… æˆåŠŸæ›´æ–°æ­·å²æª”æ¡ˆï¼Œæ–°å¢è¨˜éŒ„: {new_date} -> {new_record['è™Ÿç¢¼1']}, {new_record['è™Ÿç¢¼2']}, {new_record['è™Ÿç¢¼3']}, {new_record['è™Ÿç¢¼4']}, {new_record['è™Ÿç¢¼5']}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ­·å²æª”æ¡ˆå¤±æ•—: {e}")
            return False

def main():
    """ä¸»ç¨‹å¼"""
    logger.info("ğŸ² åŠ å·Fantasy 5æ¯æ—¥é–‹ççˆ¬èŸ²")
    logger.info("="*60)
    
    crawler = Fantasy5DailyCrawler()
    
    # çˆ¬å–ç•¶æ—¥é–‹ççµæœ
    results = crawler.crawl_daily_results()
    
    if results:
        logger.info(f"ğŸ‰ æˆåŠŸç²å– {len(results)} ç­†ç•¶æ—¥é–‹ççµæœ")
        
        # æ›´æ–°æ­·å²æª”æ¡ˆ
        for result in results:
            success = crawler.update_history_file(result)
            if success:
                logger.info("âœ… æ­·å²æª”æ¡ˆæ›´æ–°æˆåŠŸ")
            else:
                logger.warning("âš ï¸ æ­·å²æª”æ¡ˆæ›´æ–°å¤±æ•—æˆ–è¨˜éŒ„å·²å­˜åœ¨")
    else:
        logger.warning("âš ï¸ æœªæ‰¾åˆ°ç•¶æ—¥é–‹ççµæœ")
        logger.info("ğŸ’¡ å¯èƒ½çš„åŸå› :")
        logger.info("   1. é–‹çæ™‚é–“æœªåˆ° (åŠ å·æ™‚é–“ 6:30 PM)")
        logger.info("   2. ç¶²ç«™çµæ§‹è®Šæ›´")
        logger.info("   3. ç¶²è·¯é€£ç·šå•é¡Œ")

if __name__ == "__main__":
    main()
