#!/usr/bin/env python3
"""
åŠ å·Fantasy 5çˆ¬èŸ²ï¼ˆå¾å°ç£å½©åˆ¸ç¶²ç«™ï¼‰
å°ˆé–€ç”¨æ–¼å¾ https://twlottery.in/en/lotteryCA5 ç²å–åŠ å·Fantasy 5æœ€æ–°é–‹çè™Ÿç¢¼
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime, timedelta
import re
import time
import logging
import pytz
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Fantasy5Crawler:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'https://twlottery.in/',
        })
        
        # æ™‚å€è¨­å®š
        self.ca_timezone = pytz.timezone('America/Los_Angeles')
        self.tw_timezone = pytz.timezone('Asia/Taipei')
        
        # ç›®æ¨™URL
        self.target_url = 'https://twlottery.in/en/lotteryCA5'
        
    def get_today_ca_date(self):
        """å–å¾—åŠ å·ä»Šå¤©çš„æ—¥æœŸ"""
        ca_now = datetime.now(self.ca_timezone)
        return ca_now.date()
    
    def get_today_tw_date(self):
        """å–å¾—å°ç£ä»Šå¤©çš„æ—¥æœŸ"""
        tw_now = datetime.now(self.tw_timezone)
        return tw_now.date()
    
    def convert_tw_date_to_ca_date(self, tw_date):
        """å°‡å°ç£æ—¥æœŸè½‰æ›ç‚ºå°æ‡‰çš„ç¾åœ‹æ—¥æœŸï¼ˆè€ƒæ…®æ™‚å·®ï¼‰"""
        try:
            # å°‡å°ç£æ—¥æœŸè½‰æ›ç‚ºdatetimeå°è±¡
            tw_datetime = datetime.combine(tw_date, datetime.min.time())
            tw_datetime = self.tw_timezone.localize(tw_datetime)
            
            # è½‰æ›ç‚ºåŠ å·æ™‚é–“
            ca_datetime = tw_datetime.astimezone(self.ca_timezone)
            ca_date = ca_datetime.date()
            
            logger.info(f"ğŸ• æ™‚å€è½‰æ›: å°ç£ {tw_date} -> åŠ å· {ca_date}")
            return ca_date
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ™‚å€è½‰æ›å¤±æ•—: {e}ï¼Œä½¿ç”¨åŸæ—¥æœŸ")
            return tw_date
    
    def crawl_latest_results(self):
        """çˆ¬å–æœ€æ–°é–‹ççµæœ"""
        logger.info("ğŸ¯ é–‹å§‹çˆ¬å–åŠ å·Fantasy 5æœ€æ–°é–‹ççµæœ...")
        
        # é¦–å…ˆå˜—è©¦ä½¿ç”¨requests
        results = self.crawl_with_requests()
        if results:
            return results
        
        # å¦‚æœrequestså¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨Selenium
        logger.info("ğŸ”„ å˜—è©¦ä½¿ç”¨Seleniumè™•ç†å‹•æ…‹å…§å®¹...")
        results = self.crawl_with_selenium()
        if results:
            return results
        
        logger.warning("âš ï¸ æ‰€æœ‰æ–¹æ³•éƒ½ç„¡æ³•ç²å–é–‹ççµæœ")
        return []
    
    def crawl_with_requests(self):
        """ä½¿ç”¨requestsçˆ¬å–"""
        try:
            # ç™¼é€è«‹æ±‚
            response = self.session.get(self.target_url, timeout=30)
            response.raise_for_status()
            
            logger.info(f"âœ… æˆåŠŸé€£æ¥åˆ° {self.target_url}")
            
            # è§£æHTML
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # å°‹æ‰¾ç›®æ¨™class
            results = self.parse_results(soup)
            
            if results:
                logger.info(f"ğŸ‰ æˆåŠŸç²å– {len(results)} ç­†é–‹ççµæœ")
                return results
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°é–‹ççµæœ")
                return []
                
        except Exception as e:
            logger.error(f"âŒ requestsçˆ¬å–å¤±æ•—: {e}")
            return []
    
    def crawl_with_selenium(self):
        """ä½¿ç”¨Seleniumçˆ¬å–å‹•æ…‹å…§å®¹"""
        driver = None
        try:
            # è¨­å®šChromeé¸é …
            chrome_options = Options()
            chrome_options.add_argument('--headless')  # ç„¡é ­æ¨¡å¼
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # å»ºç«‹WebDriver
            driver = webdriver.Chrome(options=chrome_options)
            
            logger.info("ğŸŒ ä½¿ç”¨Seleniumé–‹å•Ÿç€è¦½å™¨...")
            driver.get(self.target_url)
            
            # ç­‰å¾…é é¢è¼‰å…¥
            wait = WebDriverWait(driver, 10)
            
            # ç­‰å¾…å¯èƒ½çš„å‹•æ…‹å…§å®¹è¼‰å…¥
            time.sleep(3)
            
            # å°‹æ‰¾ç›®æ¨™å…ƒç´ 
            try:
                # å˜—è©¦å°‹æ‰¾ List_listItem__C_wls é¡åˆ¥
                elements = driver.find_elements(By.CLASS_NAME, "List_listItem__C_wls")
                logger.info(f"ğŸ” Seleniumæ‰¾åˆ° {len(elements)} å€‹ List_listItem__C_wls å…ƒç´ ")
                
                if elements:
                    results = []
                    logger.info(f"ğŸ” é–‹å§‹è§£æ {len(elements)} å€‹å…ƒç´ ...")
                    
                    for i, element in enumerate(elements):
                        try:
                            # ç²å–å…ƒç´ çš„HTMLå…§å®¹
                            element_html = element.get_attribute('outerHTML')
                            logger.info(f"ğŸ” å…ƒç´  {i+1} HTML: {element_html[:200]}...")
                            
                            # ç²å–å®Œæ•´çš„HTMLå…§å®¹
                            if i < 3:  # åªé¡¯ç¤ºå‰3å€‹å…ƒç´ çš„å®Œæ•´HTML
                                logger.info(f"ğŸ” å…ƒç´  {i+1} å®Œæ•´HTML: {element_html}")
                            
                            result = self.parse_selenium_element(element)
                            if result:
                                results.append(result)
                                logger.info(f"âœ… è§£ææˆåŠŸ: {result['date']} -> {result['numbers']}")
                            else:
                                logger.warning(f"âš ï¸ å…ƒç´  {i+1} è§£æå¤±æ•—")
                        except Exception as e:
                            logger.warning(f"âš ï¸ è§£æå…ƒç´  {i+1} å¤±æ•—: {e}")
                            continue
                    
                    if results:
                        logger.info(f"ğŸ‰ SeleniumæˆåŠŸç²å– {len(results)} ç­†é–‹ççµæœ")
                        return results
                    else:
                        logger.warning("âš ï¸ é›–ç„¶æ‰¾åˆ°äº†å…ƒç´ ï¼Œä½†ç„¡æ³•è§£æå‡ºæœ‰æ•ˆçš„é–‹ççµæœ")
                
                # å¦‚æœæ²’æ‰¾åˆ°ç›®æ¨™é¡åˆ¥ï¼Œå˜—è©¦å…¶ä»–æ–¹æ³•
                logger.info("ğŸ” å˜—è©¦å°‹æ‰¾å…¶ä»–å¯èƒ½çš„å…ƒç´ ...")
                
                # å°‹æ‰¾æ‰€æœ‰åŒ…å«æ•¸å­—çš„å…ƒç´ 
                number_elements = driver.find_elements(By.XPATH, "//*[contains(text(), '1') or contains(text(), '2') or contains(text(), '3') or contains(text(), '4') or contains(text(), '5')]")
                logger.info(f"ğŸ” æ‰¾åˆ° {len(number_elements)} å€‹åŒ…å«æ•¸å­—çš„å…ƒç´ ")
                
                # å°‹æ‰¾è¡¨æ ¼
                tables = driver.find_elements(By.TAG_NAME, "table")
                logger.info(f"ğŸ” æ‰¾åˆ° {len(tables)} å€‹è¡¨æ ¼")
                
                # å°‹æ‰¾åˆ—è¡¨
                lists = driver.find_elements(By.XPATH, "//ul | //ol")
                logger.info(f"ğŸ” æ‰¾åˆ° {len(lists)} å€‹åˆ—è¡¨")
                
                # ç²å–é é¢åŸå§‹ç¢¼
                page_source = driver.page_source
                soup = BeautifulSoup(page_source, 'html.parser')
                results = self.parse_results(soup)
                
                if results:
                    logger.info(f"ğŸ‰ å¾é é¢åŸå§‹ç¢¼æˆåŠŸç²å– {len(results)} ç­†é–‹ççµæœ")
                    return results
                
            except Exception as e:
                logger.warning(f"âš ï¸ å°‹æ‰¾å…ƒç´ å¤±æ•—: {e}")
            
            logger.warning("âš ï¸ Seleniumæœªæ‰¾åˆ°é–‹ççµæœ")
            return []
            
        except Exception as e:
            logger.error(f"âŒ Seleniumçˆ¬å–å¤±æ•—: {e}")
            return []
        finally:
            if driver:
                driver.quit()
    
    def parse_selenium_element(self, element):
        """è§£æSeleniumå…ƒç´ """
        try:
            # æå–æ–‡å­—å…§å®¹
            text = element.text
            logger.info(f"ğŸ” å…ƒç´ æ–‡å­—å…§å®¹: {text}")
            
            # æå–æ—¥æœŸ - å˜—è©¦å¤šç¨®æ ¼å¼
            date_obj = None
            
            # æ ¼å¼1: "Sun, Oct 26, 2025"
            date_match = re.search(r'(\w{3}, \w{3} \d{1,2}, \d{4})', text)
            if date_match:
                try:
                    date_str = date_match.group(1)
                    date_obj = datetime.strptime(date_str, '%a, %b %d, %Y').date()
                    logger.info(f"ğŸ” æ‰¾åˆ°æ—¥æœŸæ ¼å¼1: {date_str} -> {date_obj}")
                except:
                    pass
            
            # æ ¼å¼2: "2025-10-26"
            if not date_obj:
                date_match = re.search(r'(\d{4}-\d{2}-\d{2})', text)
                if date_match:
                    try:
                        date_str = date_match.group(1)
                        date_obj = datetime.strptime(date_str, '%Y-%m-%d').date()
                        logger.info(f"ğŸ” æ‰¾åˆ°æ—¥æœŸæ ¼å¼2: {date_str} -> {date_obj}")
                    except:
                        pass
            
            # æ ¼å¼3: "10/26/2025"
            if not date_obj:
                date_match = re.search(r'(\d{1,2}/\d{1,2}/\d{4})', text)
                if date_match:
                    try:
                        date_str = date_match.group(1)
                        date_obj = datetime.strptime(date_str, '%m/%d/%Y').date()
                        logger.info(f"ğŸ” æ‰¾åˆ°æ—¥æœŸæ ¼å¼3: {date_str} -> {date_obj}")
                    except:
                        pass
            
            if not date_obj:
                logger.warning("âš ï¸ ç„¡æ³•è§£ææ—¥æœŸ")
                return None
            
            # å°‡å°ç£æ—¥æœŸè½‰æ›ç‚ºç¾åœ‹æ—¥æœŸ
            ca_date = self.convert_tw_date_to_ca_date(date_obj)
            
            # æå–è™Ÿç¢¼ - ä½¿ç”¨BeautifulSoupè§£æHTML
            element_html = element.get_attribute('outerHTML')
            soup = BeautifulSoup(element_html, 'html.parser')
            
            # å°‹æ‰¾ Ball_ball__Mmfkz é¡åˆ¥çš„å…ƒç´ 
            ball_elements = soup.find_all(class_='Ball_ball__Mmfkz')
            logger.info(f"ğŸ” æ‰¾åˆ° {len(ball_elements)} å€‹çƒå…ƒç´ ")
            
            numbers = []
            for ball in ball_elements:
                ball_text = ball.get_text().strip()
                if ball_text.isdigit():
                    num = int(ball_text)
                    if 1 <= num <= 39:
                        numbers.append(num)
                        logger.info(f"ğŸ” æ‰¾åˆ°è™Ÿç¢¼: {num}")
            
            if len(numbers) < 5:
                logger.warning(f"âš ï¸ è™Ÿç¢¼ä¸è¶³ï¼Œåªæ‰¾åˆ° {len(numbers)} å€‹: {numbers}")
                return None
            
            # åªå–å‰5å€‹è™Ÿç¢¼ä¸¦æ’åº
            result_numbers = sorted(numbers[:5])
            logger.info(f"âœ… è§£ææˆåŠŸ: å°ç£ {date_obj} -> åŠ å· {ca_date} -> {result_numbers}")
            
            return {
                'date': ca_date,  # ä½¿ç”¨è½‰æ›å¾Œçš„ç¾åœ‹æ—¥æœŸ
                'numbers': result_numbers
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æSeleniumå…ƒç´ å¤±æ•—: {e}")
            return None
    
    def parse_results(self, soup):
        """è§£æé–‹ççµæœ"""
        results = []
        
        # é¦–å…ˆæª¢æŸ¥æ‰€æœ‰å¯èƒ½çš„é¡åˆ¥
        logger.info("ğŸ” æª¢æŸ¥ç¶²ç«™çµæ§‹...")
        
        # å°‹æ‰¾æ‰€æœ‰åŒ…å« 'list' çš„é¡åˆ¥
        list_classes = soup.find_all(class_=re.compile(r'list', re.I))
        logger.info(f"ğŸ” æ‰¾åˆ° {len(list_classes)} å€‹åŒ…å« 'list' çš„é¡åˆ¥")
        
        # å°‹æ‰¾æ‰€æœ‰åŒ…å« 'item' çš„é¡åˆ¥
        item_classes = soup.find_all(class_=re.compile(r'item', re.I))
        logger.info(f"ğŸ” æ‰¾åˆ° {len(item_classes)} å€‹åŒ…å« 'item' çš„é¡åˆ¥")
        
        # å°‹æ‰¾æ‰€æœ‰åŒ…å« 'result' çš„é¡åˆ¥
        result_classes = soup.find_all(class_=re.compile(r'result', re.I))
        logger.info(f"ğŸ” æ‰¾åˆ° {len(result_classes)} å€‹åŒ…å« 'result' çš„é¡åˆ¥")
        
        # å°‹æ‰¾æ‰€æœ‰åŒ…å« 'number' çš„é¡åˆ¥
        number_classes = soup.find_all(class_=re.compile(r'number', re.I))
        logger.info(f"ğŸ” æ‰¾åˆ° {len(number_classes)} å€‹åŒ…å« 'number' çš„é¡åˆ¥")
        
        # æª¢æŸ¥æ‰€æœ‰å¯èƒ½çš„é¡åˆ¥åç¨±
        all_classes = set()
        for element in soup.find_all(class_=True):
            for class_name in element.get('class', []):
                all_classes.add(class_name)
        
        logger.info(f"ğŸ” ç¶²ç«™ä¸Šæ‰€æœ‰é¡åˆ¥åç¨±: {sorted(list(all_classes))[:20]}...")  # åªé¡¯ç¤ºå‰20å€‹
        
        # å˜—è©¦å°‹æ‰¾ List_listItem__C_wls é¡åˆ¥
        list_items = soup.find_all(class_='List_listItem__C_wls')
        logger.info(f"ğŸ” æ‰¾åˆ° {len(list_items)} å€‹ List_listItem__C_wls å…ƒç´ ")
        
        # å¦‚æœæ²’æ‰¾åˆ°ï¼Œå˜—è©¦å…¶ä»–å¯èƒ½çš„é¡åˆ¥
        if not list_items:
            # å˜—è©¦å°‹æ‰¾å…¶ä»–å¯èƒ½çš„é¡åˆ¥
            possible_classes = [
                'list-item',
                'result-item',
                'draw-item',
                'game-item',
                'lottery-item'
            ]
            
            for class_name in possible_classes:
                items = soup.find_all(class_=class_name)
                if items:
                    logger.info(f"ğŸ” æ‰¾åˆ° {len(items)} å€‹ {class_name} å…ƒç´ ")
                    list_items = items
                    break
        
        # å¦‚æœé‚„æ˜¯æ²’æ‰¾åˆ°ï¼Œå˜—è©¦å°‹æ‰¾åŒ…å«æ•¸å­—çš„å…ƒç´ 
        if not list_items:
            # å°‹æ‰¾å¯èƒ½åŒ…å«é–‹çè™Ÿç¢¼çš„å…ƒç´ 
            number_elements = soup.find_all(text=re.compile(r'\d{1,2}'))
            logger.info(f"ğŸ” æ‰¾åˆ° {len(number_elements)} å€‹åŒ…å«æ•¸å­—çš„æ–‡å­—å…ƒç´ ")
            
            # å°‹æ‰¾è¡¨æ ¼
            tables = soup.find_all('table')
            logger.info(f"ğŸ” æ‰¾åˆ° {len(tables)} å€‹è¡¨æ ¼")
            
            # å°‹æ‰¾åˆ—è¡¨
            lists = soup.find_all(['ul', 'ol'])
            logger.info(f"ğŸ” æ‰¾åˆ° {len(lists)} å€‹åˆ—è¡¨")
        
        for item in list_items:
            try:
                result = self.parse_single_result(item)
                if result:
                    results.append(result)
                    logger.info(f"âœ… è§£ææˆåŠŸ: {result['date']} -> {result['numbers']}")
            except Exception as e:
                logger.warning(f"âš ï¸ è§£æå–®ä¸€çµæœå¤±æ•—: {e}")
                continue
        
        return results
    
    def parse_single_result(self, item):
        """è§£æå–®ä¸€é–‹ççµæœ"""
        try:
            # æå–æ—¥æœŸ
            date_text = self.extract_date(item)
            if not date_text:
                return None
            
            # æå–è™Ÿç¢¼
            numbers = self.extract_numbers(item)
            if len(numbers) < 5:
                return None
            
            return {
                'date': date_text,
                'numbers': sorted(numbers[:5])
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æå–®ä¸€çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def extract_date(self, item):
        """å¾å…ƒç´ ä¸­æå–æ—¥æœŸ"""
        # å°‹æ‰¾æ—¥æœŸç›¸é—œçš„æ–‡å­—
        date_patterns = [
            r'(\d{4}-\d{2}-\d{2})',  # YYYY-MM-DD
            r'(\d{2}/\d{2}/\d{4})',  # MM/DD/YYYY
            r'(\d{1,2}/\d{1,2}/\d{4})',  # M/D/YYYY
        ]
        
        item_text = item.get_text()
        
        for pattern in date_patterns:
            match = re.search(pattern, item_text)
            if match:
                date_str = match.group(1)
                try:
                    # å˜—è©¦è§£ææ—¥æœŸ
                    if '-' in date_str:
                        return datetime.strptime(date_str, '%Y-%m-%d').date()
                    elif '/' in date_str:
                        return datetime.strptime(date_str, '%m/%d/%Y').date()
                except:
                    continue
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™æº–æ ¼å¼ï¼Œå˜—è©¦å°‹æ‰¾å…¶ä»–æ—¥æœŸè¡¨ç¤º
        logger.debug(f"æœªæ‰¾åˆ°æ¨™æº–æ—¥æœŸæ ¼å¼ï¼Œå…ƒç´ æ–‡å­—: {item_text[:200]}...")
        return None
    
    def extract_numbers(self, item):
        """å¾å…ƒç´ ä¸­æå–è™Ÿç¢¼"""
        numbers = []
        
        # å°‹æ‰¾æ‰€æœ‰å¯èƒ½çš„è™Ÿç¢¼å…ƒç´ 
        number_elements = item.find_all(['span', 'div', 'td', 'li'], class_=re.compile(r'number|ball|digit', re.I))
        
        if not number_elements:
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç‰¹å®šçš„è™Ÿç¢¼å…ƒç´ ï¼Œå¾æ–‡å­—ä¸­æå–
            item_text = item.get_text()
            numbers = re.findall(r'\b(\d{1,2})\b', item_text)
        else:
            # å¾è™Ÿç¢¼å…ƒç´ ä¸­æå–
            for element in number_elements:
                text = element.get_text().strip()
                if text.isdigit() and 1 <= int(text) <= 39:
                    numbers.append(text)
        
        # è½‰æ›ç‚ºæ•´æ•¸ä¸¦éæ¿¾æœ‰æ•ˆç¯„åœ
        valid_numbers = []
        for num in numbers:
            try:
                num_int = int(num)
                if 1 <= num_int <= 39:
                    valid_numbers.append(num_int)
            except:
                continue
        
        return valid_numbers
    
    def format_result(self, result):
        """æ ¼å¼åŒ–çµæœç‚ºExcelæ ¼å¼"""
        date_obj = result['date']
        numbers = result['numbers']
        
        # ç”ŸæˆæœŸåˆ¥è™Ÿç¢¼
        year = date_obj.year % 100
        month = date_obj.month
        day = date_obj.day
        period = f"{year:02d}{month:02d}{day:02d}001"
        
        # å–å¾—ä¸­æ–‡æ˜ŸæœŸ
        weekdays = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥']
        weekday = weekdays[date_obj.weekday()]
        
        return {
            'æ—¥æœŸ': date_obj.strftime('%Y-%m-%d %H:%M:%S'),
            'æ˜ŸæœŸ': weekday,
            'è™Ÿç¢¼1': numbers[0],
            'è™Ÿç¢¼2': numbers[1],
            'è™Ÿç¢¼3': numbers[2],
            'è™Ÿç¢¼4': numbers[3],
            'è™Ÿç¢¼5': numbers[4],
            'æœŸåˆ¥': period
        }
    
    def save_results(self, results):
        """ä¿å­˜çµæœåˆ°Excelæª”æ¡ˆï¼Œåˆä½µåˆ°ç¾æœ‰æ­·å²æª”æ¡ˆ"""
        if not results:
            logger.warning("âš ï¸ æ²’æœ‰çµæœå¯ä¿å­˜")
            return False
        
        try:
            # æ ¼å¼åŒ–çµæœ
            formatted_results = []
            for result in results:
                formatted_result = self.format_result(result)
                formatted_results.append(formatted_result)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ç¾æœ‰çš„æ­·å²æª”æ¡ˆ
            history_filename = "fantasy5_hist.xlsx"
            if pd.io.common.file_exists(history_filename):
                logger.info(f"ğŸ“ è®€å–ç¾æœ‰æ­·å²æª”æ¡ˆ: {history_filename}")
                try:
                    existing_df = pd.read_excel(history_filename, engine='openpyxl')
                    logger.info(f"ğŸ“Š ç¾æœ‰è¨˜éŒ„æ•¸: {len(existing_df)} ç­†")
                except Exception as e:
                    logger.warning(f"âš ï¸ è®€å–ç¾æœ‰æª”æ¡ˆå¤±æ•—: {e}ï¼Œå°‡å»ºç«‹æ–°æª”æ¡ˆ")
                    existing_df = pd.DataFrame(columns=['æ—¥æœŸ', 'æ˜ŸæœŸ', 'è™Ÿç¢¼1', 'è™Ÿç¢¼2', 'è™Ÿç¢¼3', 'è™Ÿç¢¼4', 'è™Ÿç¢¼5', 'æœŸåˆ¥'])
            else:
                logger.info("ğŸ“ å»ºç«‹æ–°çš„æ­·å²æª”æ¡ˆ")
                existing_df = pd.DataFrame(columns=['æ—¥æœŸ', 'æ˜ŸæœŸ', 'è™Ÿç¢¼1', 'è™Ÿç¢¼2', 'è™Ÿç¢¼3', 'è™Ÿç¢¼4', 'è™Ÿç¢¼5', 'æœŸåˆ¥'])
            
            # å»ºç«‹æ–°çµæœçš„DataFrame
            new_df = pd.DataFrame(formatted_results)
            
            # æª¢æŸ¥é‡è¤‡è¨˜éŒ„
            new_records = []
            existing_dates = set()
            
            if not existing_df.empty:
                # å–å¾—ç¾æœ‰è¨˜éŒ„çš„æ—¥æœŸ
                for _, row in existing_df.iterrows():
                    date_str = str(row['æ—¥æœŸ'])[:10]  # åªå–æ—¥æœŸéƒ¨åˆ†
                    existing_dates.add(date_str)
            
            # éæ¿¾æ–°è¨˜éŒ„
            for _, row in new_df.iterrows():
                date_str = str(row['æ—¥æœŸ'])[:10]  # åªå–æ—¥æœŸéƒ¨åˆ†
                if date_str not in existing_dates:
                    new_records.append(row)
                    logger.info(f"âœ… æ–°å¢è¨˜éŒ„: {date_str} -> {row['è™Ÿç¢¼1']}, {row['è™Ÿç¢¼2']}, {row['è™Ÿç¢¼3']}, {row['è™Ÿç¢¼4']}, {row['è™Ÿç¢¼5']}")
                else:
                    logger.info(f"âš ï¸ è·³éé‡è¤‡è¨˜éŒ„: {date_str}")
            
            if not new_records:
                logger.info("â„¹ï¸ æ²’æœ‰æ–°çš„è¨˜éŒ„éœ€è¦æ·»åŠ ")
                return True
            
            # åˆä½µè¨˜éŒ„
            new_records_df = pd.DataFrame(new_records)
            
            # ç¢ºä¿æ—¥æœŸæ ¼å¼ä¸€è‡´
            if not existing_df.empty:
                # å°‡ç¾æœ‰è³‡æ–™çš„æ—¥æœŸè½‰æ›ç‚ºå­—ä¸²æ ¼å¼
                existing_df['æ—¥æœŸ'] = existing_df['æ—¥æœŸ'].astype(str)
            
            if not new_records_df.empty:
                # å°‡æ–°è³‡æ–™çš„æ—¥æœŸè½‰æ›ç‚ºå­—ä¸²æ ¼å¼
                new_records_df['æ—¥æœŸ'] = new_records_df['æ—¥æœŸ'].astype(str)
            
            updated_df = pd.concat([existing_df, new_records_df], ignore_index=True)
            
            # æŒ‰æ—¥æœŸæ’åº
            updated_df = updated_df.sort_values('æ—¥æœŸ')
            
            # ä¿å­˜æ›´æ–°å¾Œçš„æª”æ¡ˆ
            updated_df.to_excel(history_filename, index=False, engine='openpyxl')
            
            logger.info(f"âœ… æ­·å²æª”æ¡ˆå·²æ›´æ–°: {history_filename}")
            logger.info(f"ğŸ“Š ç¸½è¨˜éŒ„æ•¸: {len(updated_df)} ç­†")
            logger.info(f"ğŸ“ˆ æ–°å¢è¨˜éŒ„æ•¸: {len(new_records)} ç­†")
            
            # é¡¯ç¤ºæœ€æ–°çµæœ
            if new_records:
                latest = new_records[-1]  # æœ€æ–°çš„è¨˜éŒ„
                logger.info(f"ğŸ¯ æœ€æ–°é–‹ççµæœ:")
                logger.info(f"   æ—¥æœŸ: {latest['æ—¥æœŸ']}")
                logger.info(f"   è™Ÿç¢¼: {latest['è™Ÿç¢¼1']}, {latest['è™Ÿç¢¼2']}, {latest['è™Ÿç¢¼3']}, {latest['è™Ÿç¢¼4']}, {latest['è™Ÿç¢¼5']}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜çµæœå¤±æ•—: {e}")
            return False

def main():
    """ä¸»ç¨‹å¼"""
    logger.info("ğŸ² åŠ å·Fantasy 5çˆ¬èŸ²")
    logger.info("="*60)
    
    crawler = Fantasy5Crawler()
    
    # çˆ¬å–æœ€æ–°é–‹ççµæœ
    results = crawler.crawl_latest_results()
    
    if results:
        # ä¿å­˜çµæœ
        success = crawler.save_results(results)
        if success:
            logger.info("âœ… ç¨‹å¼åŸ·è¡Œå®Œæˆ")
        else:
            logger.error("âŒ ä¿å­˜çµæœå¤±æ•—")
    else:
        logger.warning("âš ï¸ æœªæ‰¾åˆ°é–‹ççµæœ")
        logger.info("ğŸ’¡ å¯èƒ½çš„åŸå› :")
        logger.info("   1. ç¶²ç«™çµæ§‹è®Šæ›´")
        logger.info("   2. ç¶²è·¯é€£ç·šå•é¡Œ")
        logger.info("   3. ç¶²ç«™æš«æ™‚ç„¡æ³•è¨ªå•")

if __name__ == "__main__":
    main()
