#!/usr/bin/env python3
"""
åŠ å·Fantasy 5é–‹çè™Ÿç¢¼çˆ¬èŸ²
æ ¼å¼èˆ‡539æ­·å²ç´€éŒ„ä¿æŒä¸€è‡´
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import re
import time
import logging
from typing import List, Dict, Optional

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CaliforniaFantasy5Crawler:
    def __init__(self):
        self.base_url = "https://www.calottery.com"
        self.fantasy5_url = "https://www.calottery.com/fantasy-5"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
        
    def get_weekday_chinese(self, date_obj):
        """å°‡æ—¥æœŸè½‰æ›ç‚ºä¸­æ–‡æ˜ŸæœŸ"""
        weekdays = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥']
        return weekdays[date_obj.weekday()]
    
    def parse_date(self, date_str):
        """è§£ææ—¥æœŸå­—ä¸²ï¼Œæ”¯æ´å¤šç¨®æ ¼å¼"""
        date_formats = [
            '%Y-%m-%d',
            '%m/%d/%Y',
            '%m-%d-%Y',
            '%B %d, %Y',
            '%b %d, %Y'
        ]
        
        for fmt in date_formats:
            try:
                return datetime.strptime(date_str.strip(), fmt)
            except ValueError:
                continue
        
        logger.warning(f"ç„¡æ³•è§£ææ—¥æœŸæ ¼å¼: {date_str}")
        return None
    
    def crawl_calottery_results(self):
        """å¾åŠ å·å½©ç¥¨å®˜æ–¹ç¶²ç«™çˆ¬å–Fantasy 5é–‹ççµæœ"""
        try:
            logger.info("ğŸ•·ï¸ é–‹å§‹çˆ¬å–åŠ å·Fantasy 5é–‹ççµæœ...")
            
            response = self.session.get(self.fantasy5_url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            results = []
            
            # å°‹æ‰¾é–‹ççµæœè¡¨æ ¼æˆ–åˆ—è¡¨
            # åŠ å·å½©ç¥¨ç¶²ç«™çµæ§‹å¯èƒ½ä¸åŒï¼Œéœ€è¦æ ¹æ“šå¯¦éš›HTMLèª¿æ•´
            result_elements = soup.find_all(['div', 'table', 'ul'], class_=re.compile(r'result|draw|winning|number', re.I))
            
            for element in result_elements:
                # å˜—è©¦æå–æ—¥æœŸå’Œè™Ÿç¢¼
                date_match = re.search(r'(\d{1,2}[/-]\d{1,2}[/-]\d{4}|\d{4}[/-]\d{1,2}[/-]\d{1,2})', str(element))
                numbers_match = re.findall(r'\b(\d{1,2})\b', str(element))
                
                if date_match and len(numbers_match) >= 5:
                    date_str = date_match.group(1)
                    parsed_date = self.parse_date(date_str)
                    
                    if parsed_date:
                        # å–å‰5å€‹æ•¸å­—ä½œç‚ºé–‹çè™Ÿç¢¼
                        winning_numbers = [int(num) for num in numbers_match[:5]]
                        
                        if all(1 <= num <= 39 for num in winning_numbers):
                            results.append({
                                'date': parsed_date,
                                'numbers': winning_numbers
                            })
                            logger.info(f"âœ… æ‰¾åˆ°é–‹ççµæœ: {parsed_date.strftime('%Y-%m-%d')} -> {winning_numbers}")
            
            if not results:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°é–‹ççµæœï¼Œå˜—è©¦å‚™ç”¨æ–¹æ³•...")
                return self.crawl_alternative_source()
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ çˆ¬å–åŠ å·å½©ç¥¨ç¶²ç«™å¤±æ•—: {e}")
            return self.crawl_alternative_source()
    
    def crawl_alternative_source(self):
        """å‚™ç”¨æ•¸æ“šä¾†æº"""
        try:
            logger.info("ğŸ”„ å˜—è©¦å‚™ç”¨æ•¸æ“šä¾†æº...")
            
            # å˜—è©¦ç¬¬ä¸‰æ–¹ç¶²ç«™
            alternative_urls = [
                "https://www.lotteryusa.com/california/fantasy-5/",
                "https://www.lotterypost.com/game/california-fantasy-5",
            ]
            
            for url in alternative_urls:
                try:
                    response = self.session.get(url, timeout=30)
                    response.raise_for_status()
                    
                    soup = BeautifulSoup(response.content, 'html.parser')
                    results = self.parse_alternative_results(soup)
                    
                    if results:
                        logger.info(f"âœ… å¾å‚™ç”¨ä¾†æºç²å– {len(results)} ç­†çµæœ")
                        return results
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ å‚™ç”¨ä¾†æº {url} å¤±æ•—: {e}")
                    continue
            
            # å¦‚æœæ‰€æœ‰ä¾†æºéƒ½å¤±æ•—ï¼Œè¿”å›ç©ºçµæœ
            logger.error("âŒ æ‰€æœ‰æ•¸æ“šä¾†æºéƒ½å¤±æ•—")
            return []
            
        except Exception as e:
            logger.error(f"âŒ å‚™ç”¨æ•¸æ“šä¾†æºå¤±æ•—: {e}")
            return []
    
    def parse_alternative_results(self, soup):
        """è§£æå‚™ç”¨ä¾†æºçš„çµæœ"""
        results = []
        
        # æ ¹æ“šå¸¸è¦‹çš„ç¬¬ä¸‰æ–¹ç¶²ç«™çµæ§‹è§£æ
        # é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›ç¶²ç«™çµæ§‹èª¿æ•´
        result_rows = soup.find_all(['tr', 'div'], class_=re.compile(r'result|draw|winning', re.I))
        
        for row in result_rows:
            try:
                # æå–æ—¥æœŸ
                date_text = row.get_text()
                date_match = re.search(r'(\d{1,2}[/-]\d{1,2}[/-]\d{4})', date_text)
                
                if date_match:
                    date_str = date_match.group(1)
                    parsed_date = self.parse_date(date_str)
                    
                    if parsed_date:
                        # æå–è™Ÿç¢¼
                        numbers = re.findall(r'\b(\d{1,2})\b', date_text)
                        winning_numbers = [int(num) for num in numbers if 1 <= int(num) <= 39]
                        
                        if len(winning_numbers) >= 5:
                            results.append({
                                'date': parsed_date,
                                'numbers': winning_numbers[:5]
                            })
                            
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æå‚™ç”¨çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        return results
    
    def generate_period_number(self, date_obj):
        """ç”ŸæˆæœŸåˆ¥è™Ÿç¢¼ï¼Œæ ¼å¼é¡ä¼¼539"""
        # ä½¿ç”¨æ—¥æœŸç”ŸæˆæœŸåˆ¥è™Ÿç¢¼
        # æ ¼å¼: YYMMDDXXX (å¹´æœˆæ—¥+åºè™Ÿ)
        year = date_obj.year % 100
        month = date_obj.month
        day = date_obj.day
        
        # ç”ŸæˆæœŸåˆ¥è™Ÿç¢¼
        period = f"{year:02d}{month:02d}{day:02d}001"
        return period
    
    def format_results_to_dataframe(self, results: List[Dict]) -> pd.DataFrame:
        """å°‡çˆ¬å–çµæœæ ¼å¼åŒ–ç‚ºDataFrameï¼Œèˆ‡539æ ¼å¼ä¸€è‡´"""
        if not results:
            logger.warning("âš ï¸ æ²’æœ‰çµæœéœ€è¦æ ¼å¼åŒ–")
            return pd.DataFrame()
        
        formatted_data = []
        
        for result in results:
            date_obj = result['date']
            numbers = result['numbers']
            
            # ç¢ºä¿æœ‰5å€‹è™Ÿç¢¼
            if len(numbers) != 5:
                logger.warning(f"âš ï¸ è™Ÿç¢¼æ•¸é‡ä¸æ­£ç¢º: {numbers}")
                continue
            
            # æŒ‰539æ ¼å¼æ•´ç†æ•¸æ“š
            formatted_row = {
                'æ—¥æœŸ': date_obj.strftime('%Y-%m-%d %H:%M:%S'),
                'æ˜ŸæœŸ': self.get_weekday_chinese(date_obj),
                'è™Ÿç¢¼1': numbers[0],
                'è™Ÿç¢¼2': numbers[1], 
                'è™Ÿç¢¼3': numbers[2],
                'è™Ÿç¢¼4': numbers[3],
                'è™Ÿç¢¼5': numbers[4],
                'æœŸåˆ¥': self.generate_period_number(date_obj)
            }
            
            formatted_data.append(formatted_row)
            logger.info(f"ğŸ“Š æ ¼å¼åŒ–çµæœ: {date_obj.strftime('%Y-%m-%d')} -> {numbers}")
        
        df = pd.DataFrame(formatted_data)
        logger.info(f"âœ… æˆåŠŸæ ¼å¼åŒ– {len(df)} ç­†åŠ å·Fantasy 5é–‹ççµæœ")
        
        return df
    
    def save_to_excel(self, df: pd.DataFrame, filename: str = "fantasy5_hist.xlsx"):
        """ä¿å­˜çµæœåˆ°Excelæª”æ¡ˆ"""
        try:
            if df.empty:
                logger.warning("âš ï¸ æ²’æœ‰æ•¸æ“šéœ€è¦ä¿å­˜")
                return False
            
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
            if Path(filename).exists():
                # è®€å–ç¾æœ‰æ•¸æ“š
                existing_df = pd.read_excel(filename, engine='openpyxl')
                
                # åˆä½µæ•¸æ“šï¼Œé¿å…é‡è¤‡
                combined_df = pd.concat([existing_df, df], ignore_index=True)
                
                # ç§»é™¤é‡è¤‡è¨˜éŒ„ï¼ˆåŸºæ–¼æ—¥æœŸï¼‰
                combined_df = combined_df.drop_duplicates(subset=['æ—¥æœŸ'], keep='last')
                combined_df = combined_df.sort_values('æ—¥æœŸ')
                
                logger.info(f"ğŸ“Š åˆä½µæ•¸æ“š: åŸæœ‰ {len(existing_df)} ç­†ï¼Œæ–°å¢ {len(df)} ç­†ï¼Œåˆè¨ˆ {len(combined_df)} ç­†")
                
            else:
                combined_df = df
                logger.info(f"ğŸ“Š å»ºç«‹æ–°æª”æ¡ˆï¼ŒåŒ…å« {len(df)} ç­†æ•¸æ“š")
            
            # ä¿å­˜åˆ°Excel
            combined_df.to_excel(filename, index=False, engine='openpyxl')
            logger.info(f"âœ… åŠ å·Fantasy 5æ­·å²æ•¸æ“šå·²ä¿å­˜åˆ°: {filename}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜Excelæª”æ¡ˆå¤±æ•—: {e}")
            return False
    
    def crawl_and_save(self, filename: str = "fantasy5_hist.xlsx"):
        """å®Œæ•´çš„çˆ¬å–å’Œä¿å­˜æµç¨‹"""
        logger.info("ğŸ² é–‹å§‹åŠ å·Fantasy 5æ•¸æ“šçˆ¬å–æµç¨‹")
        logger.info("="*60)
        
        # çˆ¬å–æ•¸æ“š
        results = self.crawl_calottery_results()
        
        if not results:
            logger.error("âŒ æœªèƒ½ç²å–ä»»ä½•é–‹ççµæœ")
            return False
        
        # æ ¼å¼åŒ–æ•¸æ“š
        df = self.format_results_to_dataframe(results)
        
        if df.empty:
            logger.error("âŒ æ•¸æ“šæ ¼å¼åŒ–å¤±æ•—")
            return False
        
        # ä¿å­˜åˆ°Excel
        success = self.save_to_excel(df, filename)
        
        if success:
            logger.info("ğŸ‰ åŠ å·Fantasy 5æ•¸æ“šçˆ¬å–å®Œæˆï¼")
            return True
        else:
            logger.error("âŒ æ•¸æ“šä¿å­˜å¤±æ•—")
            return False

def main():
    """ä¸»ç¨‹å¼"""
    crawler = CaliforniaFantasy5Crawler()
    success = crawler.crawl_and_save()
    
    if success:
        print("âœ… åŠ å·Fantasy 5çˆ¬èŸ²åŸ·è¡ŒæˆåŠŸ")
        return True
    else:
        print("âŒ åŠ å·Fantasy 5çˆ¬èŸ²åŸ·è¡Œå¤±æ•—")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
