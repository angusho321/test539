import pandas as pd
import numpy as np
from itertools import combinations
from collections import defaultdict
import datetime
import os
import json
import sys
import argparse
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# ==========================================
# è¨­å®šå€
# ==========================================
FILE_539 = 'lottery_hist.xlsx'
FILE_FANTASY = 'fantasy5_hist.xlsx'

OUTPUT_539 = 'best_strategies_539.xlsx'
OUTPUT_FANTASY = 'best_strategies_fantasy5.xlsx'

# æ™‚é–“æ®µå®šç¾© (å°æ‡‰ Python weekday: 0=é€±ä¸€ ... 6=é€±æ—¥)
TIME_WINDOWS_539 = {
    "å‘¨ä¸€è‡³å‘¨ä¸‰": [0, 1, 2],  # é€±ä¸€ã€é€±äºŒã€é€±ä¸‰
    "å‘¨äºŒè‡³å‘¨å››": [1, 2, 3],  # é€±äºŒã€é€±ä¸‰ã€é€±å››
    "å‘¨ä¸‰è‡³å‘¨äº”": [2, 3, 4],  # é€±ä¸‰ã€é€±å››ã€é€±äº”
    "å‘¨å››è‡³å‘¨å…­": [3, 4, 5]   # é€±å››ã€é€±äº”ã€é€±å…­
}

TIME_WINDOWS_FANTASY = {
    "å‘¨ä¸€è‡³å‘¨ä¸‰": [0, 1, 2],  # é€±ä¸€ã€é€±äºŒã€é€±ä¸‰
    "å‘¨äºŒè‡³å‘¨å››": [1, 2, 3],  # é€±äºŒã€é€±ä¸‰ã€é€±å››
    "å‘¨ä¸‰è‡³å‘¨äº”": [2, 3, 4],  # é€±ä¸‰ã€é€±å››ã€é€±äº”
    "å‘¨å››è‡³å‘¨å…­": [3, 4, 5],  # é€±å››ã€é€±äº”ã€é€±å…­
    "å‘¨äº”è‡³å‘¨æ—¥": [4, 5, 6]   # é€±äº”ã€é€±å…­ã€é€±æ—¥ï¼ˆåƒ…å¤©å¤©æ¨‚ï¼‰
}

def get_time_windows(is_fantasy=False):
    """æ ¹æ“šå½©çƒé¡å‹è¿”å›å°æ‡‰çš„æ™‚é–“æ®µ"""
    return TIME_WINDOWS_FANTASY if is_fantasy else TIME_WINDOWS_539

# ä½¿ç”¨è¿‘ä¸€å¹´çš„ç´€éŒ„
RECENT_YEARS = 1

# ==========================================
# æ ¸å¿ƒæ¼”ç®—æ³•
# ==========================================

def load_data(file_path, is_fantasy=False):
    """è®€å–è³‡æ–™ä¸¦è™•ç†æ™‚å€ï¼Œåªä¿ç•™è¿‘ä¸€å¹´çš„ç´€éŒ„"""
    df = None
    
    # å…ˆå˜—è©¦è®€å– Excel
    if os.path.exists(file_path):
        try:
            df = pd.read_excel(file_path, engine='openpyxl')
        except Exception as e:
            print(f"   âš ï¸ è®€å– Excel å¤±æ•—: {e}ï¼Œå˜—è©¦ CSV...")
    
    # å¦‚æœ Excel ä¸å­˜åœ¨æˆ–è®€å–å¤±æ•—ï¼Œå˜—è©¦ CSV
    if df is None:
        # å˜—è©¦å¤šç¨®å¯èƒ½çš„ CSV æª”å
        csv_paths = [
            file_path.replace('.xlsx', '.csv'),
            file_path.replace('.xlsx', ' - Sheet1.csv'),
            file_path + ' - Sheet1.csv'
        ]
        
        for csv_path in csv_paths:
            if os.path.exists(csv_path):
                try:
                    df = pd.read_csv(csv_path, encoding='utf-8-sig')
                    print(f"   ğŸ“„ å¾ CSV è®€å–: {csv_path}")
                    break
                except Exception as e:
                    print(f"   âš ï¸ è®€å– CSV å¤±æ•— ({csv_path}): {e}")
                    continue
    
    if df is None:
        print(f"âŒ ç„¡æ³•è®€å–æ–‡ä»¶: {file_path}")
        return None

    # è™•ç†æ—¥æœŸæ¬„ä½ï¼šæ”¯æ´å¤šç¨®æ—¥æœŸæ ¼å¼ï¼ˆåŒ…å«æˆ–ä¸åŒ…å«æ™‚é–“ï¼‰
    try:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='mixed', errors='coerce')
        if df['æ—¥æœŸ'].isna().any():
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y-%m-%d %H:%M:%S', errors='coerce')
        if df['æ—¥æœŸ'].isna().any():
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y-%m-%d', errors='coerce')
    except:
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    
    # ç§»é™¤ç„¡æ³•è§£æçš„æ—¥æœŸè¡Œ
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    # æ™‚å€è™•ç†
    if is_fantasy:
        # å¤©å¤©æ¨‚: ç¾åœ‹æ™‚é–“ + 1å¤© = å°ç£ä¸‹æ³¨æ™‚é–“
        df['Analysis_Date'] = df['æ—¥æœŸ'] + pd.Timedelta(days=1)
    else:
        # 539: ä¸éœ€è¦è½‰æ›
        df['Analysis_Date'] = df['æ—¥æœŸ']
    
    # è¨ˆç®—è¿‘ä¸€å¹´çš„æ—¥æœŸç¯„åœ
    max_date = df['Analysis_Date'].max()
    cutoff_date = max_date - pd.Timedelta(days=365 * RECENT_YEARS)
    
    # åªä¿ç•™è¿‘ä¸€å¹´çš„ç´€éŒ„
    df = df[df['Analysis_Date'] >= cutoff_date].copy()
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€èˆŠçš„åœ¨å‰ï¼‰
    df = df.sort_values('Analysis_Date', ascending=True).reset_index(drop=True)
    
    print(f"   ğŸ“Š å·²è¼‰å…¥ {len(df)} ç­†è¿‘ä¸€å¹´ç´€éŒ„")
    if len(df) > 0:
        print(f"   ğŸ“… æ—¥æœŸç¯„åœ: {df['Analysis_Date'].min()} è‡³ {df['Analysis_Date'].max()}")
    
    return df

def extract_numbers(row, is_fantasy=False):
    """å¾è³‡æ–™åˆ—ä¸­æå–è™Ÿç¢¼"""
    try:
        if 'è™Ÿç¢¼1' in row.index:
            nums = [int(row['è™Ÿç¢¼1']), int(row['è™Ÿç¢¼2']), int(row['è™Ÿç¢¼3']), 
                   int(row['è™Ÿç¢¼4']), int(row['è™Ÿç¢¼5'])]
        else:
            # å˜—è©¦å…¶ä»–å¯èƒ½çš„æ¬„ä½åç¨±
            cols = row.index.tolist()
            nums = [int(row[cols[2]]), int(row[cols[3]]), int(row[cols[4]]), 
                   int(row[cols[5]]), int(row[cols[6]])]
        return set(nums)
    except:
        return None

def calculate_window_win_rate(df, window_name, window_days, is_fantasy=False):
    """
    è¨ˆç®—æŒ‡å®šæ™‚é–“æ®µçš„å‹ç‡ï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰
    è¦å‰‡ï¼šä¸‰å€‹è™Ÿç¢¼ä¸­ä»»ä¸€å€‹åœ¨è©²æ™‚é–“æ®µï¼ˆä¸‰å¤©ï¼‰çš„ä»»ä¸€å¤©å‡ºç¾å³ç®—ä¸­ç
    
    è¿”å›: [{'combo': tuple, 'win_rate': float, 'wins': int, 'total': int, 'missed_dates': list}, ...]
    """
    # éæ¿¾å‡ºè©²æ™‚é–“æ®µçš„è³‡æ–™
    window_data = df[df['Analysis_Date'].dt.weekday.isin(window_days)].copy()
    
    if len(window_data) == 0:
        return []
    
    # é å…ˆæå–æ‰€æœ‰è™Ÿç¢¼é›†åˆï¼Œé¿å…é‡è¤‡è¨ˆç®—
    window_data['Numbers'] = window_data.apply(
        lambda row: extract_numbers(row, is_fantasy), axis=1
    )
    window_data = window_data[window_data['Numbers'].notna()].copy()
    
    # å°‡è³‡æ–™æŒ‰é€±åˆ†çµ„ï¼Œä¸¦é å…ˆè¨ˆç®—æ¯é€±çš„è™Ÿç¢¼è¯é›†
    window_data['YearWeek'] = window_data['Analysis_Date'].apply(
        lambda x: (x.isocalendar()[0], x.isocalendar()[1])
    )
    
    # é å…ˆè¨ˆç®—æ¯é€±çš„è™Ÿç¢¼è¯é›†ï¼ˆè©²é€±æ™‚é–“æ®µå…§æ‰€æœ‰é–‹å‡ºçš„è™Ÿç¢¼ï¼‰
    # åŒæ™‚è¨˜éŒ„æ¯é€±çš„æ™‚é–“æ®µç¬¬ä¸€å¤©æ—¥æœŸ
    week_unions = {}
    week_first_dates = {}  # è¨˜éŒ„æ¯é€±çš„æ™‚é–“æ®µç¬¬ä¸€å¤©æ—¥æœŸ
    
    # æ™‚é–“æ®µçš„ç¬¬ä¸€å¤©ï¼ˆweekdayæœ€å°çš„é‚£å¤©ï¼‰
    first_weekday = min(window_days)
    
    for (year, week), group in window_data.groupby('YearWeek'):
        union_set = set()
        for nums in group['Numbers']:
            if nums:
                union_set.update(nums)
        week_unions[(year, week)] = union_set
        
        # æ‰¾åˆ°è©²é€±ä¸­æ™‚é–“æ®µçš„ç¬¬ä¸€å¤©ï¼ˆweekdayç‚ºfirst_weekdayçš„é‚£å¤©ï¼‰
        first_day_records = group[group['Analysis_Date'].dt.weekday == first_weekday]
        if len(first_day_records) > 0:
            first_day = first_day_records['Analysis_Date'].min()
            week_first_dates[(year, week)] = first_day.date()
        else:
            # å¦‚æœè©²é€±æ²’æœ‰ç¬¬ä¸€å¤©ï¼ˆä¾‹å¦‚è©²é€±çš„ç¬¬ä¸€å¤©é‚„æ²’é–‹çï¼‰ï¼Œä½¿ç”¨è©²é€±æ™‚é–“æ®µå…§æœ€æ—©çš„é‚£å¤©
            first_day = group['Analysis_Date'].min()
            week_first_dates[(year, week)] = first_day.date()
    
    total_weeks = len(week_unions)
    if total_weeks == 0:
        return []
    
    # ç²å–æ‰€æœ‰å¯èƒ½çš„3ç¢¼çµ„åˆ
    max_num = 39 if not is_fantasy else 39  # 539å’ŒFantasy5éƒ½æ˜¯1-39
    all_combos = list(combinations(range(1, max_num + 1), 3))
    total_combos = len(all_combos)
    
    results = []
    
    # é¡¯ç¤ºé€²åº¦
    print(f"         è¨ˆç®—ä¸­... (å…± {total_combos} çµ„çµ„åˆ, {total_weeks} é€±)", end='', flush=True)
    
    for idx, combo in enumerate(all_combos):
        # æ¯1000å€‹çµ„åˆé¡¯ç¤ºä¸€æ¬¡é€²åº¦
        if idx % 1000 == 0 and idx > 0:
            progress = (idx / total_combos) * 100
            print(f"\r         é€²åº¦: {progress:.1f}% ({idx}/{total_combos})", end='', flush=True)
        
        combo_set = set(combo)
        wins = 0
        missed_dates = []  # è¨˜éŒ„æœªä¸­ççš„æ™‚é–“æ®µç¬¬ä¸€å¤©æ—¥æœŸ
        
        # ä½¿ç”¨é å…ˆè¨ˆç®—çš„é€±è¯é›†ï¼Œå¿«é€Ÿåˆ¤æ–·
        for (year, week), week_union in week_unions.items():
            # å¦‚æœçµ„åˆèˆ‡è©²é€±çš„è™Ÿç¢¼è¯é›†æœ‰äº¤é›†ï¼Œå‰‡ä¸­ç
            if not combo_set.isdisjoint(week_union):
                wins += 1
            else:
                # æœªä¸­çï¼Œè¨˜éŒ„è©²é€±çš„æ™‚é–“æ®µç¬¬ä¸€å¤©æ—¥æœŸ
                first_date = week_first_dates.get((year, week))
                if first_date:
                    missed_dates.append(first_date)
        
        win_rate = wins / total_weeks
        results.append({
            'combo': combo,
            'win_rate': win_rate,
            'wins': wins,
            'total': total_weeks,
            'missed_dates': sorted(missed_dates)  # æŒ‰æ—¥æœŸæ’åº
        })
    
    # æŒ‰å‹ç‡æ’åº
    results.sort(key=lambda x: x['win_rate'], reverse=True)
    print(f"\r         å®Œæˆï¼æ‰¾åˆ° {len(results)} çµ„çµæœ" + " " * 40)  # æ¸…é™¤é€²åº¦é¡¯ç¤º
    
    # å…ˆå–å‰30åé€²è¡Œå»é‡è™•ç†ï¼ˆç¢ºä¿æœ‰è¶³å¤ çš„å€™é¸ï¼‰
    top_results = results[:30]
    
    # ç§»é™¤é‡è¤‡å…©ç¢¼çµ„åˆçš„ç­–ç•¥
    deduplicated_results = remove_duplicate_two_ball_combos(top_results)
    
    # è¿”å›å»é‡å¾Œçš„å‰10å
    return deduplicated_results[:10]

def remove_duplicate_two_ball_combos(results):
    """
    ç§»é™¤é‡è¤‡å…©ç¢¼çµ„åˆçš„ç­–ç•¥ï¼Œåªä¿ç•™å‹ç‡æœ€é«˜çš„
    ä¾‹å¦‚ï¼š07,22,24 å’Œ 07,24,28 éƒ½æœ‰ 07,24ï¼Œåªä¿ç•™å‹ç‡è¼ƒé«˜çš„
    å¦‚æœå‹ç‡ç›¸åŒï¼Œåªä¿ç•™ç¬¬ä¸€å€‹ï¼ˆæŒ‰åŸå§‹é †åºï¼‰
    """
    if not results:
        return results
    
    # å»ºç«‹å…©ç¢¼çµ„åˆåˆ°æœ€ä½³ä¸‰ç¢¼çµ„åˆçš„æ˜ å°„
    two_ball_to_best = {}  # {(ball1, ball2): best_result}
    
    # ç¬¬ä¸€éï¼šæ‰¾å‡ºæ¯å€‹å…©ç¢¼çµ„åˆå°æ‡‰çš„æœ€ä½³ä¸‰ç¢¼çµ„åˆ
    for result in results:
        combo = result['combo']
        # æå–æ‰€æœ‰å¯èƒ½çš„å…©ç¢¼å­çµ„åˆï¼ˆC(3,2) = 3å€‹ï¼‰
        two_ball_combos = list(combinations(combo, 2))
        
        for two_ball in two_ball_combos:
            # æ’åºå…©ç¢¼çµ„åˆï¼Œç¢ºä¿ä¸€è‡´æ€§
            two_ball_sorted = tuple(sorted(two_ball))
            
            # å¦‚æœé€™å€‹å…©ç¢¼çµ„åˆé‚„æ²’è¨˜éŒ„ï¼Œæˆ–ç•¶å‰çµ„åˆå‹ç‡æ›´é«˜ï¼Œå‰‡æ›´æ–°
            if two_ball_sorted not in two_ball_to_best:
                two_ball_to_best[two_ball_sorted] = result
            else:
                # æ¯”è¼ƒå‹ç‡ï¼Œä¿ç•™å‹ç‡æ›´é«˜çš„
                current_best = two_ball_to_best[two_ball_sorted]
                if result['win_rate'] > current_best['win_rate']:
                    two_ball_to_best[two_ball_sorted] = result
                # å¦‚æœå‹ç‡ç›¸åŒï¼Œæ¯”è¼ƒä¸­çæ¬¡æ•¸
                elif result['win_rate'] == current_best['win_rate']:
                    if result['wins'] > current_best['wins']:
                        two_ball_to_best[two_ball_sorted] = result
                    # å¦‚æœå‹ç‡å’Œä¸­çæ¬¡æ•¸éƒ½ç›¸åŒï¼Œä¿ç•™ç¬¬ä¸€å€‹ï¼ˆä¸æ›´æ–°ï¼‰
    
    # ç¬¬äºŒéï¼šæ‰¾å‡ºæ‰€æœ‰æ‡‰è©²è¢«ä¿ç•™çš„ä¸‰ç¢¼çµ„åˆ
    # ä¸€å€‹ä¸‰ç¢¼çµ„åˆè¦è¢«ä¿ç•™ï¼Œç•¶ä¸”åƒ…ç•¶å®ƒè‡³å°‘æœ‰ä¸€å€‹å…©ç¢¼å­çµ„åˆæ˜¯è©²å…©ç¢¼çµ„åˆçš„æœ€ä½³é¸æ“‡
    kept_combos = set()
    for two_ball, best_result in two_ball_to_best.items():
        kept_combos.add(best_result['combo'])
    
    # æ”¶é›†æ‰€æœ‰è¢«ä¿ç•™çš„çµ„åˆï¼Œä¿æŒåŸå§‹é †åº
    final_results = []
    seen_combos = set()
    for result in results:
        if result['combo'] in kept_combos and result['combo'] not in seen_combos:
            final_results.append(result)
            seen_combos.add(result['combo'])
    
    # æŒ‰å‹ç‡é‡æ–°æ’åºï¼ˆç¢ºä¿é †åºæ­£ç¢ºï¼‰
    final_results.sort(key=lambda x: (x['win_rate'], x['wins']), reverse=True)
    
    return final_results

def format_combo_result(result):
    """æ ¼å¼åŒ–çµ„åˆçµæœ"""
    combo_str = ",".join(f"{x:02d}" for x in result['combo'])
    win_rate_pct = result['win_rate'] * 100
    return f"{combo_str} [{win_rate_pct:.1f}% ({result['wins']}/{result['total']})]"

def format_missed_dates(missed_dates):
    """æ ¼å¼åŒ–æœªä¸­çæ—¥æœŸï¼ˆé¡¯ç¤ºæ‰€æœ‰æ—¥æœŸï¼‰"""
    if not missed_dates:
        return ""
    
    # æ ¼å¼åŒ–ç‚º YYYY/MM/DDï¼Œé¡¯ç¤ºæ‰€æœ‰æ—¥æœŸ
    formatted_dates = [date.strftime('%Y/%m/%d') if hasattr(date, 'strftime') else str(date) for date in missed_dates]
    
    return ", ".join(formatted_dates)

def generate_predictions(df, is_fantasy=False):
    """
    ç”Ÿæˆæ‰€æœ‰æ™‚é–“æ®µçš„é æ¸¬
    è¿”å›: DataFrameï¼ŒåŒ…å«å„æ™‚é–“æ®µçš„å‹ç‡å‰ååå’Œæ§“é¾œæ—¥æœŸ
    """
    print(f"   ğŸ” é–‹å§‹è¨ˆç®—å„æ™‚é–“æ®µå‹ç‡...")
    
    # æ ¹æ“šå½©çƒé¡å‹ç²å–å°æ‡‰çš„æ™‚é–“æ®µ
    time_windows = get_time_windows(is_fantasy)
    
    # è¨ˆç®—æ¯å€‹æ™‚é–“æ®µçš„å‹ç‡å‰åå
    window_results = {}
    for window_name, window_days in time_windows.items():
        print(f"      -> è¨ˆç®— {window_name}...")
        results = calculate_window_win_rate(df, window_name, window_days, is_fantasy)
        window_results[window_name] = results
    
    # æ§‹å»ºè¼¸å‡º DataFrame
    # æ‰¾å‡ºæœ€é•·çš„çµæœåˆ—è¡¨ï¼ˆæœ€å¤š10å€‹ï¼‰
    max_len = max(len(results) for results in window_results.values()) if window_results else 0
    
    # å‹•æ…‹å‰µå»ºè¼¸å‡ºæ•¸æ“šï¼ˆæ ¹æ“šæ™‚é–“æ®µï¼Œæ¯å€‹æ™‚é–“æ®µå¾Œé¢åŠ ä¸€å€‹æ§“é¾œæ¬„ä½ï¼‰
    # æ§‹å»ºæ¬„ä½é †åºå’Œæ•¸æ“š
    columns = []
    data_dict = {}
    window_to_missed = {}  # å»ºç«‹æ™‚é–“æ®µåç¨±åˆ°æ§“é¾œæ¬„ä½åç¨±çš„å°æ‡‰é—œä¿‚
    
    # ç‚ºæ¯å€‹æ™‚é–“æ®µå‰µå»ºå…©å€‹æ¬„ä½ï¼šæ™‚é–“æ®µåç¨±å’Œã€Œæ§“é¾œ1ã€ã€ã€Œæ§“é¾œ2ã€ç­‰
    missed_counter = 1
    for window_name in time_windows.keys():
        columns.append(window_name)
        missed_col_name = f"æ§“é¾œ{missed_counter}"
        columns.append(missed_col_name)
        # åˆå§‹åŒ–æ•¸æ“šåˆ—è¡¨
        data_dict[window_name] = []
        data_dict[missed_col_name] = []
        # è¨˜éŒ„å°æ‡‰é—œä¿‚
        window_to_missed[window_name] = missed_col_name
        missed_counter += 1
    
    for i in range(max_len):
        for window_name in time_windows.keys():
            missed_col_name = window_to_missed[window_name]
            if i < len(window_results[window_name]):
                result = window_results[window_name][i]
                data_dict[window_name].append(format_combo_result(result))
                # æ ¼å¼åŒ–æ§“é¾œæ—¥æœŸï¼ˆé¡¯ç¤ºæ‰€æœ‰æ—¥æœŸï¼‰
                missed_dates = result.get('missed_dates', [])
                data_dict[missed_col_name].append(format_missed_dates(missed_dates))
            else:
                data_dict[window_name].append("")
                data_dict[missed_col_name].append("")
    
    # å‰µå»º DataFrame
    result_df = pd.DataFrame({col: data_dict[col] for col in columns})
    result_df = result_df[columns]  # ç¢ºä¿æ¬„ä½é †åºæ­£ç¢º
    
    return result_df

# ==========================================
# Google Drive ä¸Šå‚³
# ==========================================
def upload_to_drive(local_file, file_id=None, folder_id=None, creds_json=None):
    """
    ä¸Šå‚³æ–‡ä»¶åˆ° Google Drive
    å„ªå…ˆä½¿ç”¨æ–‡ä»¶ ID æ›´æ–°ç¾æœ‰æ–‡ä»¶ï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨è³‡æ–™å¤¾ ID å‰µå»ºæ–°æ–‡ä»¶
    å¦‚æœæœ¬åœ°æ–‡ä»¶æ˜¯ CSVï¼Œæœƒè½‰æ›ç‚º XLSX æ ¼å¼ä¸Šå‚³
    """
    if not os.path.exists(local_file):
        print(f"âŒ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_file}")
        return False
    
    if not creds_json:
        print(f"âš ï¸ æœªè¨­ç½® GOOGLE_CREDENTIALS")
        return False

    try:
        # è§£æèªè­‰è³‡è¨Š
        if isinstance(creds_json, str):
            creds_dict = json.loads(creds_json)
        else:
            creds_dict = creds_json
        
        creds = service_account.Credentials.from_service_account_info(
            creds_dict, scopes=['https://www.googleapis.com/auth/drive']
        )
        service = build('drive', 'v3', credentials=creds)
        file_name = os.path.basename(local_file)
        
        # ç²å–æœå‹™å¸³è™Ÿéƒµä»¶ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰
        service_account_email = creds_dict.get('client_email', 'unknown')
        print(f"ğŸ” ä½¿ç”¨æœå‹™å¸³è™Ÿ: {service_account_email}")

        # å¦‚æœæœ¬åœ°æ–‡ä»¶æ˜¯ CSVï¼Œè½‰æ›ç‚º XLSXï¼ˆå› ç‚º Google Drive ä¸Šçš„æ–‡ä»¶æ˜¯ XLSXï¼‰
        upload_file = local_file
        # æ ¹æ“šæ–‡ä»¶æ“´å±•åè¨­ç½®æ­£ç¢ºçš„ MIME type
        if local_file.endswith('.xlsx'):
            upload_mime_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        elif local_file.endswith('.csv'):
            upload_mime_type = 'text/csv'
            # è½‰æ› CSV ç‚º XLSX
            xlsx_file = local_file.replace('.csv', '.xlsx')
            try:
                df = pd.read_csv(local_file, encoding='utf-8-sig')
                df.to_excel(xlsx_file, index=False, engine='openpyxl')
                upload_file = xlsx_file
                upload_mime_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                print(f"ğŸ“Š å·²å°‡ CSV è½‰æ›ç‚º XLSX: {xlsx_file}")
            except Exception as e:
                print(f"âš ï¸ CSV è½‰æ›ç‚º XLSX å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹ CSV: {e}")
                # ç¹¼çºŒä½¿ç”¨ CSV
        else:
            # å…¶ä»–æ–‡ä»¶é¡å‹ï¼Œå˜—è©¦æ¨æ–· MIME type
            upload_mime_type = 'application/octet-stream'
        
        # å¦‚æœç›®æ¨™æ–‡ä»¶æ˜¯ XLSXï¼Œæ›´æ–°æ–‡ä»¶å
        if file_id:
            # æª¢æŸ¥ç›®æ¨™æ–‡ä»¶é¡å‹
            try:
                file_info = service.files().get(fileId=file_id, fields='name,mimeType').execute()
                target_name = file_info.get('name', '')
                if target_name.endswith('.xlsx') and upload_file.endswith('.csv'):
                    # ç›®æ¨™æ˜¯ XLSXï¼Œä½†æˆ‘å€‘æœ‰ CSVï¼Œéœ€è¦è½‰æ›
                    if not upload_file.endswith('.xlsx'):
                        xlsx_file = local_file.replace('.csv', '.xlsx')
                        df = pd.read_csv(local_file, encoding='utf-8-sig')
                        df.to_excel(xlsx_file, index=False, engine='openpyxl')
                        upload_file = xlsx_file
                        upload_mime_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                        print(f"ğŸ“Š å·²å°‡ CSV è½‰æ›ç‚º XLSX ä»¥åŒ¹é…ç›®æ¨™æ–‡ä»¶æ ¼å¼")
            except:
                pass  # å¦‚æœç„¡æ³•ç²å–æ–‡ä»¶è³‡è¨Šï¼Œç¹¼çºŒä½¿ç”¨åŸå§‹æ–‡ä»¶

        media = MediaFileUpload(upload_file, mimetype=upload_mime_type)

        # å„ªå…ˆå˜—è©¦ä½¿ç”¨æ–‡ä»¶ ID æ›´æ–°ç¾æœ‰æ–‡ä»¶
        if file_id:
            try:
                print(f"ğŸ” å˜—è©¦æ›´æ–°ç¾æœ‰æ–‡ä»¶ ID: {file_id}")
                # é©—è­‰æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ¬Šé™
                file_info = service.files().get(
                    fileId=file_id,
                    fields='id,name,parents,mimeType'
                ).execute()
                print(f"âœ… æ–‡ä»¶é©—è­‰æˆåŠŸ: {file_info.get('name', 'æœªçŸ¥')}")
                print(f"   ğŸ“ æ–‡ä»¶ ID: {file_info.get('id')}")
                print(f"   ğŸ“‚ çˆ¶è³‡æ–™å¤¾: {file_info.get('parents', ['æ ¹ç›®éŒ„'])}")
                
                # æ›´æ–°æ–‡ä»¶
                updated_file = service.files().update(
                    fileId=file_id,
                    media_body=media,
                    fields='id,name,webViewLink'
                ).execute()
                print(f"âœ… [Drive] æ›´æ–°æ–‡ä»¶: {updated_file.get('name')} (ID: {file_id})")
                print(f"   ğŸ”— æª¢è¦–é€£çµ: {updated_file.get('webViewLink', 'N/A')}")
                
                # æ¸…ç†è‡¨æ™‚å‰µå»ºçš„ XLSX æ–‡ä»¶ï¼ˆå¦‚æœåŸå§‹æ˜¯ CSVï¼‰
                if upload_file != local_file and upload_file.endswith('.xlsx'):
                    try:
                        os.remove(upload_file)
                        print(f"ğŸ§¹ å·²æ¸…ç†è‡¨æ™‚æ–‡ä»¶: {upload_file}")
                    except:
                        pass
                
                return True
            except Exception as update_error:
                error_msg = str(update_error)
                if '404' in error_msg or 'notFound' in error_msg:
                    print(f"âš ï¸ æ–‡ä»¶ ID ä¸å­˜åœ¨æˆ–ç„¡æ¬Šé™ï¼Œå˜—è©¦å‰µå»ºæ–°æ–‡ä»¶...")
                else:
                    print(f"âš ï¸ æ›´æ–°æ–‡ä»¶å¤±æ•—: {update_error}")
                    print(f"   å˜—è©¦å…¶ä»–è§£æ±ºæ–¹æ¡ˆ...")

        # å¦‚æœæ²’æœ‰æ–‡ä»¶ ID æˆ–æ›´æ–°å¤±æ•—ï¼Œå˜—è©¦æœç´¢ç¾æœ‰æ–‡ä»¶æˆ–å‰µå»ºæ–°æ–‡ä»¶
        # å„ªå…ˆåœ¨æ ¹ç›®éŒ„æœç´¢ï¼ˆèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰ï¼Œå¦‚æœæä¾›äº†è³‡æ–™å¤¾ ID å‰‡åœ¨è³‡æ–™å¤¾ä¸­æœç´¢
        try:
            # æœç´¢æ–‡ä»¶åï¼ˆå¦‚æœæœ¬åœ°æ˜¯ CSVï¼Œæœç´¢å°æ‡‰çš„ XLSX æ–‡ä»¶åï¼‰
            search_name = file_name.replace('.csv', '.xlsx') if file_name.endswith('.csv') else file_name
            print(f"ğŸ” å˜—è©¦æœç´¢ç¾æœ‰æ–‡ä»¶: {search_name}")
            
            # æ§‹å»ºæœç´¢æŸ¥è©¢
            if folder_id:
                # åœ¨æŒ‡å®šè³‡æ–™å¤¾ä¸­æœç´¢
                print(f"   ğŸ“ åœ¨è³‡æ–™å¤¾ä¸­æœç´¢ (ID: {folder_id})")
                query = f"name = '{search_name}' and '{folder_id}' in parents and trashed = false"
            else:
                # åœ¨æ ¹ç›®éŒ„æœç´¢ï¼ˆä¸æŒ‡å®š parentsï¼Œèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰
                print(f"   ğŸ“ åœ¨æ ¹ç›®éŒ„æœç´¢ï¼ˆèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰")
                query = f"name = '{search_name}' and trashed = false"
                # æ’é™¤åœ¨è³‡æ–™å¤¾ä¸­çš„æ–‡ä»¶ï¼ˆåªæœç´¢æ ¹ç›®éŒ„ï¼‰
                # æ³¨æ„ï¼šGoogle Drive API ç„¡æ³•ç›´æ¥æœç´¢æ ¹ç›®éŒ„ï¼Œæˆ‘å€‘éœ€è¦å…ˆæœç´¢æ‰€æœ‰åŒåæ–‡ä»¶ï¼Œç„¶å¾Œéæ¿¾
            
            # æœç´¢æ–‡ä»¶
            # å¦‚æœæ²’æœ‰æŒ‡å®šè³‡æ–™å¤¾ï¼Œæœç´¢æ‰€æœ‰åŒåæ–‡ä»¶ï¼ˆåŒ…æ‹¬æ ¹ç›®éŒ„å’Œè³‡æ–™å¤¾ä¸­çš„ï¼‰
            if not folder_id:
                # æœç´¢æ‰€æœ‰åŒåæ–‡ä»¶
                query = f"name = '{search_name}' and trashed = false"
            
            results = service.files().list(q=query, fields="files(id, name, parents)").execute()
            existing_files = results.get('files', [])
            
            # å¦‚æœæ²’æœ‰æŒ‡å®šè³‡æ–™å¤¾ï¼Œå„ªå…ˆé¸æ“‡æ ¹ç›®éŒ„çš„æ–‡ä»¶ï¼ˆèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰
            if not folder_id and existing_files:
                # å˜—è©¦æ‰¾åˆ°èˆ‡å…¶ä»–æ–‡ä»¶ï¼ˆå¦‚ fantasy5_hist.xlsxï¼‰åŒè·¯å¾‘çš„æ–‡ä»¶
                # å…ˆç²å–ä¸€å€‹åƒè€ƒæ–‡ä»¶çš„ parentsï¼ˆå¦‚æœå¯èƒ½ï¼‰
                try:
                    # å˜—è©¦ç²å– fantasy5_hist æˆ– prediction_log çš„ parents ä½œç‚ºåƒè€ƒ
                    ref_file_id = os.environ.get('FANTASY5_HIST_FILE_ID') or os.environ.get('FANTASY5_PREDICTION_LOG_FILE_ID')
                    if ref_file_id:
                        ref_info = service.files().get(fileId=ref_file_id, fields='parents').execute()
                        ref_parents = ref_info.get('parents', [])
                        # å„ªå…ˆé¸æ“‡èˆ‡åƒè€ƒæ–‡ä»¶ç›¸åŒ parents çš„æ–‡ä»¶
                        matching_files = [f for f in existing_files if f.get('parents', []) == ref_parents]
                        if matching_files:
                            existing_files = matching_files
                except:
                    pass  # å¦‚æœç„¡æ³•ç²å–åƒè€ƒï¼Œä½¿ç”¨æ‰€æœ‰æ‰¾åˆ°çš„æ–‡ä»¶
            
            if existing_files:
                # æ‰¾åˆ°ç¾æœ‰æ–‡ä»¶ï¼Œæ›´æ–°å®ƒ
                existing_file_id = existing_files[0]['id']
                existing_file_name = existing_files[0]['name']
                print(f"ğŸ“„ æ‰¾åˆ°ç¾æœ‰æ–‡ä»¶: {existing_file_name} (ID: {existing_file_id})")
                updated_file = service.files().update(
                    fileId=existing_file_id,
                    media_body=media,
                    fields='id,name,webViewLink'
                ).execute()
                print(f"âœ… [Drive] æ›´æ–°ç¾æœ‰æ–‡ä»¶: {updated_file.get('name')} (ID: {existing_file_id})")
                print(f"   ğŸ”— æª¢è¦–é€£çµ: {updated_file.get('webViewLink', 'N/A')}")
                print(f"   ğŸ’¡ å»ºè­°å°‡æ­¤æ–‡ä»¶ ID ({existing_file_id}) æ–°å¢ç‚º GitHub Secret")
                
                # æ¸…ç†è‡¨æ™‚å‰µå»ºçš„ XLSX æ–‡ä»¶ï¼ˆå¦‚æœåŸå§‹æ˜¯ CSVï¼‰
                if upload_file != local_file and upload_file.endswith('.xlsx'):
                    try:
                        os.remove(upload_file)
                        print(f"ğŸ§¹ å·²æ¸…ç†è‡¨æ™‚æ–‡ä»¶: {upload_file}")
                    except:
                        pass
                
                return True
            else:
                # æ²’æœ‰æ‰¾åˆ°ç¾æœ‰æ–‡ä»¶ï¼Œå‰µå»ºæ–°æ–‡ä»¶
                print(f"ğŸ“ æœªæ‰¾åˆ°ç¾æœ‰æ–‡ä»¶ï¼Œå‰µå»ºæ–°æ–‡ä»¶...")
                create_name = search_name if upload_file.endswith('.xlsx') else file_name
                file_metadata = {
                    'name': create_name
                }
                
                # å¦‚æœæŒ‡å®šäº†è³‡æ–™å¤¾ï¼Œè¨­å®šçˆ¶è³‡æ–™å¤¾ï¼›å¦å‰‡å‰µå»ºåœ¨æ ¹ç›®éŒ„
                if folder_id:
                    file_metadata['parents'] = [folder_id]
                    print(f"   ğŸ“ ç›®æ¨™è³‡æ–™å¤¾ ID: {folder_id}")
                else:
                    print(f"   ğŸ“ å‰µå»ºåœ¨æ ¹ç›®éŒ„ï¼ˆèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰")
                
                created_file = service.files().create(
                    body=file_metadata,
                    media_body=media,
                    fields='id,name,webViewLink'
                ).execute()
                print(f"âœ… [Drive] æ–°å¢æ–‡ä»¶: {created_file.get('name')}")
                print(f"   ğŸ“ æ–‡ä»¶ ID: {created_file.get('id')}")
                print(f"   ğŸ”— æª¢è¦–é€£çµ: {created_file.get('webViewLink', 'N/A')}")
                print(f"   ğŸ’¡ å»ºè­°å°‡æ­¤æ–‡ä»¶ ID ({created_file.get('id')}) æ–°å¢ç‚º GitHub Secret")
                
                # æ¸…ç†è‡¨æ™‚å‰µå»ºçš„ XLSX æ–‡ä»¶ï¼ˆå¦‚æœåŸå§‹æ˜¯ CSVï¼‰
                if upload_file != local_file and upload_file.endswith('.xlsx'):
                    try:
                        os.remove(upload_file)
                        print(f"ğŸ§¹ å·²æ¸…ç†è‡¨æ™‚æ–‡ä»¶: {upload_file}")
                    except:
                        pass
                
                return True
                
        except Exception as create_error:
            error_msg = str(create_error)
            print(f"âŒ [Drive] æœç´¢æˆ–å‰µå»ºæ–‡ä»¶å¤±æ•—: {create_error}")
            if '404' in error_msg or 'notFound' in error_msg:
                if folder_id:
                    print(f"   ğŸ’¡ å¦‚æœæ–‡ä»¶åœ¨æ ¹ç›®éŒ„ï¼Œè«‹ä¸è¦è¨­ç½® GOOGLE_DRIVE_FOLDER_ID")
                    print(f"   ğŸ’¡ æˆ–è€…ç›´æ¥è¨­ç½® BEST_STRATEGIES_FANTASY5_FILE_ID æˆ– BEST_STRATEGIES_539_FILE_ID")
            return False
        
        return True

    except json.JSONDecodeError as e:
        print(f"âŒ [Drive] èªè­‰è³‡è¨Šæ ¼å¼éŒ¯èª¤: {e}")
        return False
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ [Drive] ä¸Šå‚³å¤±æ•—: {error_msg}")
        
        # é‡å°å¸¸è¦‹éŒ¯èª¤æä¾›è§£æ±ºæ–¹æ¡ˆ
        if '404' in error_msg or 'notFound' in error_msg:
            print(f"   ğŸ’¡ é€™é€šå¸¸æ˜¯å› ç‚º:")
            print(f"      1. è³‡æ–™å¤¾ ID ä¸æ­£ç¢º")
            print(f"      2. æœå‹™å¸³è™Ÿæ²’æœ‰æ¬Šé™è¨ªå•è©²è³‡æ–™å¤¾")
            print(f"      3. è³‡æ–™å¤¾å·²è¢«åˆªé™¤")
            print(f"   ğŸ’¡ è§£æ±ºæ–¹æ¡ˆ:")
            print(f"      1. ç¢ºèª GOOGLE_DRIVE_FOLDER_ID æ˜¯å¦æ­£ç¢º")
            print(f"      2. åœ¨ Google Drive ä¸­åˆ†äº«è³‡æ–™å¤¾çµ¦æœå‹™å¸³è™Ÿ")
            print(f"      3. ç¢ºä¿æœå‹™å¸³è™Ÿæœ‰ã€Œç·¨è¼¯è€…ã€æ¬Šé™")
        elif '403' in error_msg or 'permission' in error_msg.lower():
            print(f"   ğŸ’¡ æ¬Šé™ä¸è¶³ï¼Œè«‹ç¢ºèªæœå‹™å¸³è™Ÿæœ‰ã€Œç·¨è¼¯è€…ã€æ¬Šé™")
        elif '401' in error_msg or 'unauthorized' in error_msg.lower():
            print(f"   ğŸ’¡ èªè­‰å¤±æ•—ï¼Œè«‹ç¢ºèª GOOGLE_CREDENTIALS æ˜¯å¦æ­£ç¢º")
        
        import traceback
        traceback.print_exc()
        return False

# ==========================================
# ä¸»æµç¨‹
# ==========================================
def process_single(name, input_file, output_file, is_fantasy, file_id=None, folder_id=None, creds=None):
    """è™•ç†å–®ä¸€å½©çƒçš„åˆ†æ"""
    print(f"\nâš¡ åˆ†æ {name} (è½‰æ›æ™‚å€: {is_fantasy})...")
    
    # è¼‰å…¥è³‡æ–™ï¼ˆåªä¿ç•™æœ€æ–°365ç­†ï¼‰
    df = load_data(input_file, is_fantasy)
    if df is None or len(df) == 0:
        print(f"âŒ æ‰¾ä¸åˆ°æˆ–ç„¡æ³•è®€å– {input_file}ï¼Œè·³é")
        return False
    
    # ç”Ÿæˆé æ¸¬
    result_df = generate_predictions(df, is_fantasy)
    
    # è¼¸å‡º XLSX
    try:
        result_df.to_excel(output_file, index=False, engine='openpyxl')
        print(f"ğŸ“„ å·²å»ºç«‹: {output_file}")
    except Exception as e:
        print(f"âŒ å»ºç«‹æ–‡ä»¶å¤±æ•—: {e}")
        return False
    
    # é©—è­‰æ–‡ä»¶ç¢ºå¯¦å­˜åœ¨
    if not os.path.exists(output_file):
        print(f"âŒ è­¦å‘Š: {output_file} å‰µå»ºå¤±æ•—")
        return False
    
    # ä¸Šå‚³åˆ° Google Drive
    if creds:
        try:
            upload_to_drive(output_file, file_id=file_id, folder_id=folder_id, creds_json=creds)
            print(f"âœ… {output_file} å·²ä¸Šå‚³åˆ° Google Drive")
        except Exception as e:
            print(f"âš ï¸ ä¸Šå‚³ {output_file} åˆ° Google Drive æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print(f"   æœ¬åœ°æ–‡ä»¶å·²å‰µå»º: {output_file}")
    else:
        print(f"âš ï¸ æœªè¨­ç½® GOOGLE_CREDENTIALS")
        print(f"   ğŸ“„ æœ¬åœ°æ–‡ä»¶å·²å‰µå»º: {output_file}")
        print(f"   ğŸ’¡ æç¤º: åœ¨ GitHub Actions ä¸­ï¼Œç’°å¢ƒè®Šæ•¸æœƒè‡ªå‹•å¾ Secrets è®€å–")
        print(f"   ğŸ’¡ æœ¬åœ°æ¸¬è©¦æ™‚ï¼Œå¯ä»¥æ‰‹å‹•è¨­ç½®ç’°å¢ƒè®Šæ•¸æˆ–è·³éä¸Šå‚³æ­¥é©Ÿ")
    
    return True

def process_all():
    """è™•ç†æ‰€æœ‰å½©çƒçš„åˆ†æï¼ˆé è¨­è¡Œç‚ºï¼‰"""
    folder_id = os.environ.get('GOOGLE_DRIVE_FOLDER_ID')
    creds = os.environ.get('GOOGLE_CREDENTIALS')
    
    file_id_539 = os.environ.get('BEST_STRATEGIES_539_FILE_ID')
    file_id_fantasy = os.environ.get('BEST_STRATEGIES_FANTASY5_FILE_ID')

    tasks = [
        ("539", FILE_539, OUTPUT_539, False, file_id_539),
        ("å¤©å¤©æ¨‚", FILE_FANTASY, OUTPUT_FANTASY, True, file_id_fantasy)
    ]

    for name, input_file, output_file, is_fantasy, file_id in tasks:
        process_single(name, input_file, output_file, is_fantasy, file_id=file_id, folder_id=folder_id, creds=creds)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='åˆ†æå½©çƒç­–ç•¥')
    parser.add_argument('--type', type=str, choices=['539', 'fantasy5', 'all'], 
                       default='all', help='æŒ‡å®šè¦åˆ†æçš„å½©çƒé¡å‹: 539, fantasy5, æˆ– all (é è¨­)')
    
    args = parser.parse_args()
    
    folder_id = os.environ.get('GOOGLE_DRIVE_FOLDER_ID')
    creds = os.environ.get('GOOGLE_CREDENTIALS')
    file_id_539 = os.environ.get('BEST_STRATEGIES_539_FILE_ID')
    file_id_fantasy = os.environ.get('BEST_STRATEGIES_FANTASY5_FILE_ID')
    
    if args.type == '539':
        print("ğŸ¯ åƒ…åˆ†æ 539...")
        process_single("539", FILE_539, OUTPUT_539, False, file_id=file_id_539, folder_id=folder_id, creds=creds)
    elif args.type == 'fantasy5':
        print("ğŸ¯ åƒ…åˆ†æå¤©å¤©æ¨‚...")
        process_single("å¤©å¤©æ¨‚", FILE_FANTASY, OUTPUT_FANTASY, True, file_id=file_id_fantasy, folder_id=folder_id, creds=creds)
    else:
        print("ğŸ¯ åˆ†ææ‰€æœ‰å½©çƒ...")
        process_all()