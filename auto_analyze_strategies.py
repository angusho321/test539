import pandas as pd
import numpy as np
from itertools import combinations
from collections import defaultdict
import datetime
import os
import json
import sys
import argparse
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# ==========================================
# è¨­å®šå€
# ==========================================
FILE_539 = 'lottery_hist.xlsx'
FILE_FANTASY = 'fantasy5_hist.xlsx'

OUTPUT_539 = 'best_strategies_539.csv'
OUTPUT_FANTASY = 'best_strategies_fantasy5.csv'

# è¦–çª—å®šç¾© (å°æ‡‰ Python weekday: 0=é€±ä¸€ ... 6=é€±æ—¥)
WINDOWS_MAPPING = {
    "é€±ä¸€~é€±ä¸‰": [0, 1, 2],
    "é€±äºŒ~é€±å››": [1, 2, 3],
    "é€±ä¸‰~é€±äº”": [2, 3, 4],
    "é€±å››~é€±å…­": [3, 4, 5]
}

# ==========================================
# æ ¸å¿ƒæ¼”ç®—æ³•
# ==========================================

def load_data(file_path, is_fantasy=False):
    """è®€å–è³‡æ–™ä¸¦è™•ç†æ™‚å€"""
    if not os.path.exists(file_path):
        return None
    
    try:
        df = pd.read_excel(file_path, engine='openpyxl')
    except:
        try:
            # å˜—è©¦è®€å– CSVï¼ˆå¯èƒ½æ˜¯ fantasy5_hist.xlsx - Sheet1.csvï¼‰
            csv_path = file_path.replace('.xlsx', '.csv')
            if not os.path.exists(csv_path):
                # å˜—è©¦å…¶ä»–å¯èƒ½çš„ CSV æª”å
                csv_path = file_path.replace('.xlsx', ' - Sheet1.csv')
            df = pd.read_csv(csv_path) # å‚™æ´
        except:
            return None

    # è™•ç†æ—¥æœŸæ¬„ä½ï¼šæ”¯æ´å¤šç¨®æ—¥æœŸæ ¼å¼ï¼ˆåŒ…å«æˆ–ä¸åŒ…å«æ™‚é–“ï¼‰
    try:
        # å…ˆå˜—è©¦è§£æç‚º datetimeï¼Œè®“ pandas è‡ªå‹•æ¨æ–·æ ¼å¼
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='mixed', errors='coerce')
        # å¦‚æœè‡ªå‹•æ¨æ–·å¤±æ•—ï¼Œå˜—è©¦å¸¸è¦‹æ ¼å¼
        if df['æ—¥æœŸ'].isna().any():
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y-%m-%d %H:%M:%S', errors='coerce')
        if df['æ—¥æœŸ'].isna().any():
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y-%m-%d', errors='coerce')
    except:
        # æœ€å¾Œå˜—è©¦ä¸æŒ‡å®šæ ¼å¼ï¼Œè®“ pandas è‡ªå‹•è™•ç†
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    
    # ç§»é™¤ç„¡æ³•è§£æçš„æ—¥æœŸè¡Œ
    df = df.dropna(subset=['æ—¥æœŸ'])
    
    # æ™‚å€è™•ç†
    if is_fantasy:
        # å¤©å¤©æ¨‚: ç¾åœ‹æ™‚é–“ + 1å¤© = å°ç£ä¸‹æ³¨æ™‚é–“
        df['Analysis_Date'] = df['æ—¥æœŸ'] + pd.Timedelta(days=1)
    else:
        # 539: ä¸éœ€è¦è½‰æ›
        df['Analysis_Date'] = df['æ—¥æœŸ']

    return df

def get_data_by_week(df):
    """å°‡è³‡æ–™è½‰æ›ç‚º {(å¹´, é€±): {æ˜ŸæœŸå¹¾: {è™Ÿç¢¼é›†åˆ}}}"""
    data = defaultdict(lambda: defaultdict(set))
    for _, row in df.iterrows():
        dt = row['Analysis_Date']
        year, week, _ = dt.isocalendar()
        weekday = dt.weekday()
        
        # å˜—è©¦æŠ“å–è™Ÿç¢¼æ¬„ä½ (ç›¸å®¹ä¸åŒå‘½å)
        try:
            # å„ªå…ˆå˜—è©¦æ¨™æº–æ¬„ä½
            if 'è™Ÿç¢¼1' in df.columns:
                nums = {row[c] for c in ['è™Ÿç¢¼1', 'è™Ÿç¢¼2', 'è™Ÿç¢¼3', 'è™Ÿç¢¼4', 'è™Ÿç¢¼5']}
            else:
                # å‡è¨­çµæ§‹å›ºå®š
                cols = df.columns
                nums = {row[cols[2]], row[cols[3]], row[cols[4]], row[cols[5]], row[cols[6]]}
        except:
            continue
            
        data[(year, week)][weekday] = nums
    return data

def calculate_stats(data_by_week, weeks_list, mode="win_rate"):
    """
    é€šç”¨è¨ˆç®—æ ¸å¿ƒ
    mode="win_rate": è¨ˆç®—å‹ç‡ (çŸ­æœŸ/é•·æœŸ)
    mode="streak": è¨ˆç®—é€£èŠ (å¾æœ€æ–°é€±å¾€å›æ¨)
    """
    results = []
    all_combos = list(combinations(range(1, 40), 3)) # 1-39è™Ÿå–3å€‹
    
    # é è™•ç†æ¯é€±çš„è™Ÿç¢¼è¯é›† (é‡å°ä¸åŒè¦–çª—)
    # week_unions[window_name][week_key] = set(all numbers in that window)
    week_unions = defaultdict(dict)
    
    # å¦‚æœæ˜¯é€£èŠæ¨¡å¼ï¼Œå¿…é ˆç¢ºä¿é€±æ¬¡æ˜¯å€’åº (æœ€æ–° -> æœ€èˆŠ)
    target_weeks = sorted(weeks_list, reverse=True) if mode == "streak" else weeks_list
    
    for window_name, days in WINDOWS_MAPPING.items():
        for w in target_weeks:
            union_set = set()
            has_data = False
            for d in days:
                if d in data_by_week[w]:
                    union_set.update(data_by_week[w][d])
                    has_data = True
            if has_data:
                week_unions[window_name][w] = union_set

    # é–‹å§‹éæ­·æ‰€æœ‰çµ„åˆ (9139çµ„)
    for combo in all_combos:
        combo_set = set(combo)
        
        for window_name in WINDOWS_MAPPING.keys():
            valid_weeks = [w for w in target_weeks if w in week_unions[window_name]]
            if len(valid_weeks) < 4 and mode == "win_rate": continue
            
            if mode == "win_rate":
                wins = 0
                for w in valid_weeks:
                    # åˆ¤æ–·ä¸­ç: çµ„åˆ èˆ‡ ç•¶é€±é–‹çè™Ÿç¢¼ æœ‰äº¤é›†
                    if not combo_set.isdisjoint(week_unions[window_name][w]):
                        wins += 1
                
                rate = wins / len(valid_weeks)
                # é–€æª»éæ¿¾
                if rate >= 0.8: # å¯¬é¬†é–€æª»ï¼Œå¾ŒçºŒç¯©é¸ Top 2
                    results.append({
                        "Window": window_name,
                        "Combo": combo,
                        "Score": rate, # æ’åºç”¨
                        "Display": f"{rate:.1%} ({wins}/{len(valid_weeks)})"
                    })
            
            elif mode == "streak":
                streak = 0
                for w in valid_weeks:
                    if not combo_set.isdisjoint(week_unions[window_name][w]):
                        streak += 1
                    else:
                        break # ä¸­æ–·
                
                if streak >= 4: # è‡³å°‘é€£4é€±æ‰ç´€éŒ„
                    results.append({
                        "Window": window_name,
                        "Combo": combo,
                        "Score": streak,
                        "Display": f"{streak}é€±"
                    })

    return pd.DataFrame(results)

def select_best_strategies(df, threshold=0.0):
    """
    æŒ‘é¸é‚è¼¯:
    1. éæ¿¾åˆ†æ•¸ < threshold
    2. é¸ç¬¬ä¸€å (Score æœ€é«˜)
    3. é¸ç¬¬äºŒå (Score æ¬¡é«˜ï¼Œä¸” Window èˆ‡ç¬¬ä¸€åä¸åŒ)
    """
    if df.empty:
        return "ç„¡æ•¸æ“š", "ç„¡æ•¸æ“š"
        
    df = df[df['Score'] >= threshold].sort_values('Score', ascending=False)
    if df.empty:
        return "ç„¡æ•¸æ“š", "ç„¡æ•¸æ“š"
        
    # ç¬¬ä¸€å
    top1 = df.iloc[0]
    
    # ç¬¬äºŒå (äº’æ–¥è¦–çª—)
    top2 = None
    for _, row in df.iterrows():
        if row['Window'] != top1['Window']:
            top2 = row
            break
            
    def format_row(row):
        nums = ",".join(f"{x:02d}" for x in row['Combo'])
        return f"ã€{row['Window']}ã€‘{nums} [{row['Display']}]"

    res1 = format_row(top1)
    res2 = format_row(top2) if top2 is not None else "ç„¡äº’æ–¥æ™‚æ®µæ•¸æ“š"
    
    return res1, res2

# ==========================================
# Google Drive ä¸Šå‚³
# ==========================================
def upload_to_drive(local_file, file_id=None, folder_id=None, creds_json=None):
    """
    ä¸Šå‚³æ–‡ä»¶åˆ° Google Drive
    å„ªå…ˆä½¿ç”¨æ–‡ä»¶ ID æ›´æ–°ç¾æœ‰æ–‡ä»¶ï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨è³‡æ–™å¤¾ ID å‰µå»ºæ–°æ–‡ä»¶
    å¦‚æœæœ¬åœ°æ–‡ä»¶æ˜¯ CSVï¼Œæœƒè½‰æ›ç‚º XLSX æ ¼å¼ä¸Šå‚³
    """
    if not os.path.exists(local_file):
        print(f"âŒ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_file}")
        return False
    
    if not creds_json:
        print(f"âš ï¸ æœªè¨­ç½® GOOGLE_CREDENTIALS")
        return False

    try:
        # è§£æèªè­‰è³‡è¨Š
        if isinstance(creds_json, str):
            creds_dict = json.loads(creds_json)
        else:
            creds_dict = creds_json
        
        creds = service_account.Credentials.from_service_account_info(
            creds_dict, scopes=['https://www.googleapis.com/auth/drive']
        )
        service = build('drive', 'v3', credentials=creds)
        file_name = os.path.basename(local_file)
        
        # ç²å–æœå‹™å¸³è™Ÿéƒµä»¶ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰
        service_account_email = creds_dict.get('client_email', 'unknown')
        print(f"ğŸ” ä½¿ç”¨æœå‹™å¸³è™Ÿ: {service_account_email}")

        # å¦‚æœæœ¬åœ°æ–‡ä»¶æ˜¯ CSVï¼Œè½‰æ›ç‚º XLSXï¼ˆå› ç‚º Google Drive ä¸Šçš„æ–‡ä»¶æ˜¯ XLSXï¼‰
        upload_file = local_file
        upload_mime_type = 'text/csv'
        if local_file.endswith('.csv'):
            # è½‰æ› CSV ç‚º XLSX
            xlsx_file = local_file.replace('.csv', '.xlsx')
            try:
                df = pd.read_csv(local_file, encoding='utf-8-sig')
                df.to_excel(xlsx_file, index=False, engine='openpyxl')
                upload_file = xlsx_file
                upload_mime_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                print(f"ğŸ“Š å·²å°‡ CSV è½‰æ›ç‚º XLSX: {xlsx_file}")
            except Exception as e:
                print(f"âš ï¸ CSV è½‰æ›ç‚º XLSX å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹ CSV: {e}")
                # ç¹¼çºŒä½¿ç”¨ CSV
        
        # å¦‚æœç›®æ¨™æ–‡ä»¶æ˜¯ XLSXï¼Œæ›´æ–°æ–‡ä»¶å
        if file_id:
            # æª¢æŸ¥ç›®æ¨™æ–‡ä»¶é¡å‹
            try:
                file_info = service.files().get(fileId=file_id, fields='name,mimeType').execute()
                target_name = file_info.get('name', '')
                if target_name.endswith('.xlsx') and upload_file.endswith('.csv'):
                    # ç›®æ¨™æ˜¯ XLSXï¼Œä½†æˆ‘å€‘æœ‰ CSVï¼Œéœ€è¦è½‰æ›
                    if not upload_file.endswith('.xlsx'):
                        xlsx_file = local_file.replace('.csv', '.xlsx')
                        df = pd.read_csv(local_file, encoding='utf-8-sig')
                        df.to_excel(xlsx_file, index=False, engine='openpyxl')
                        upload_file = xlsx_file
                        upload_mime_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                        print(f"ğŸ“Š å·²å°‡ CSV è½‰æ›ç‚º XLSX ä»¥åŒ¹é…ç›®æ¨™æ–‡ä»¶æ ¼å¼")
            except:
                pass  # å¦‚æœç„¡æ³•ç²å–æ–‡ä»¶è³‡è¨Šï¼Œç¹¼çºŒä½¿ç”¨åŸå§‹æ–‡ä»¶

        media = MediaFileUpload(upload_file, mimetype=upload_mime_type)

        # å„ªå…ˆå˜—è©¦ä½¿ç”¨æ–‡ä»¶ ID æ›´æ–°ç¾æœ‰æ–‡ä»¶
        if file_id:
            try:
                print(f"ğŸ” å˜—è©¦æ›´æ–°ç¾æœ‰æ–‡ä»¶ ID: {file_id}")
                # é©—è­‰æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ¬Šé™
                file_info = service.files().get(
                    fileId=file_id,
                    fields='id,name,parents,mimeType'
                ).execute()
                print(f"âœ… æ–‡ä»¶é©—è­‰æˆåŠŸ: {file_info.get('name', 'æœªçŸ¥')}")
                print(f"   ğŸ“ æ–‡ä»¶ ID: {file_info.get('id')}")
                print(f"   ğŸ“‚ çˆ¶è³‡æ–™å¤¾: {file_info.get('parents', ['æ ¹ç›®éŒ„'])}")
                
                # æ›´æ–°æ–‡ä»¶
                updated_file = service.files().update(
                    fileId=file_id,
                    media_body=media,
                    fields='id,name,webViewLink'
                ).execute()
                print(f"âœ… [Drive] æ›´æ–°æ–‡ä»¶: {updated_file.get('name')} (ID: {file_id})")
                print(f"   ğŸ”— æª¢è¦–é€£çµ: {updated_file.get('webViewLink', 'N/A')}")
                
                # æ¸…ç†è‡¨æ™‚å‰µå»ºçš„ XLSX æ–‡ä»¶ï¼ˆå¦‚æœåŸå§‹æ˜¯ CSVï¼‰
                if upload_file != local_file and upload_file.endswith('.xlsx'):
                    try:
                        os.remove(upload_file)
                        print(f"ğŸ§¹ å·²æ¸…ç†è‡¨æ™‚æ–‡ä»¶: {upload_file}")
                    except:
                        pass
                
                return True
            except Exception as update_error:
                error_msg = str(update_error)
                if '404' in error_msg or 'notFound' in error_msg:
                    print(f"âš ï¸ æ–‡ä»¶ ID ä¸å­˜åœ¨æˆ–ç„¡æ¬Šé™ï¼Œå˜—è©¦å‰µå»ºæ–°æ–‡ä»¶...")
                else:
                    print(f"âš ï¸ æ›´æ–°æ–‡ä»¶å¤±æ•—: {update_error}")
                    print(f"   å˜—è©¦å…¶ä»–è§£æ±ºæ–¹æ¡ˆ...")

        # å¦‚æœæ²’æœ‰æ–‡ä»¶ ID æˆ–æ›´æ–°å¤±æ•—ï¼Œå˜—è©¦æœç´¢ç¾æœ‰æ–‡ä»¶æˆ–å‰µå»ºæ–°æ–‡ä»¶
        # å„ªå…ˆåœ¨æ ¹ç›®éŒ„æœç´¢ï¼ˆèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰ï¼Œå¦‚æœæä¾›äº†è³‡æ–™å¤¾ ID å‰‡åœ¨è³‡æ–™å¤¾ä¸­æœç´¢
        try:
            # æœç´¢æ–‡ä»¶åï¼ˆå¦‚æœæœ¬åœ°æ˜¯ CSVï¼Œæœç´¢å°æ‡‰çš„ XLSX æ–‡ä»¶åï¼‰
            search_name = file_name.replace('.csv', '.xlsx') if file_name.endswith('.csv') else file_name
            print(f"ğŸ” å˜—è©¦æœç´¢ç¾æœ‰æ–‡ä»¶: {search_name}")
            
            # æ§‹å»ºæœç´¢æŸ¥è©¢
            if folder_id:
                # åœ¨æŒ‡å®šè³‡æ–™å¤¾ä¸­æœç´¢
                print(f"   ğŸ“ åœ¨è³‡æ–™å¤¾ä¸­æœç´¢ (ID: {folder_id})")
                query = f"name = '{search_name}' and '{folder_id}' in parents and trashed = false"
            else:
                # åœ¨æ ¹ç›®éŒ„æœç´¢ï¼ˆä¸æŒ‡å®š parentsï¼Œèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰
                print(f"   ğŸ“ åœ¨æ ¹ç›®éŒ„æœç´¢ï¼ˆèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰")
                query = f"name = '{search_name}' and trashed = false"
                # æ’é™¤åœ¨è³‡æ–™å¤¾ä¸­çš„æ–‡ä»¶ï¼ˆåªæœç´¢æ ¹ç›®éŒ„ï¼‰
                # æ³¨æ„ï¼šGoogle Drive API ç„¡æ³•ç›´æ¥æœç´¢æ ¹ç›®éŒ„ï¼Œæˆ‘å€‘éœ€è¦å…ˆæœç´¢æ‰€æœ‰åŒåæ–‡ä»¶ï¼Œç„¶å¾Œéæ¿¾
            
            # æœç´¢æ–‡ä»¶
            # å¦‚æœæ²’æœ‰æŒ‡å®šè³‡æ–™å¤¾ï¼Œæœç´¢æ‰€æœ‰åŒåæ–‡ä»¶ï¼ˆåŒ…æ‹¬æ ¹ç›®éŒ„å’Œè³‡æ–™å¤¾ä¸­çš„ï¼‰
            if not folder_id:
                # æœç´¢æ‰€æœ‰åŒåæ–‡ä»¶
                query = f"name = '{search_name}' and trashed = false"
            
            results = service.files().list(q=query, fields="files(id, name, parents)").execute()
            existing_files = results.get('files', [])
            
            # å¦‚æœæ²’æœ‰æŒ‡å®šè³‡æ–™å¤¾ï¼Œå„ªå…ˆé¸æ“‡æ ¹ç›®éŒ„çš„æ–‡ä»¶ï¼ˆèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰
            if not folder_id and existing_files:
                # å˜—è©¦æ‰¾åˆ°èˆ‡å…¶ä»–æ–‡ä»¶ï¼ˆå¦‚ fantasy5_hist.xlsxï¼‰åŒè·¯å¾‘çš„æ–‡ä»¶
                # å…ˆç²å–ä¸€å€‹åƒè€ƒæ–‡ä»¶çš„ parentsï¼ˆå¦‚æœå¯èƒ½ï¼‰
                try:
                    # å˜—è©¦ç²å– fantasy5_hist æˆ– prediction_log çš„ parents ä½œç‚ºåƒè€ƒ
                    ref_file_id = os.environ.get('FANTASY5_HIST_FILE_ID') or os.environ.get('FANTASY5_PREDICTION_LOG_FILE_ID')
                    if ref_file_id:
                        ref_info = service.files().get(fileId=ref_file_id, fields='parents').execute()
                        ref_parents = ref_info.get('parents', [])
                        # å„ªå…ˆé¸æ“‡èˆ‡åƒè€ƒæ–‡ä»¶ç›¸åŒ parents çš„æ–‡ä»¶
                        matching_files = [f for f in existing_files if f.get('parents', []) == ref_parents]
                        if matching_files:
                            existing_files = matching_files
                except:
                    pass  # å¦‚æœç„¡æ³•ç²å–åƒè€ƒï¼Œä½¿ç”¨æ‰€æœ‰æ‰¾åˆ°çš„æ–‡ä»¶
            
            if existing_files:
                # æ‰¾åˆ°ç¾æœ‰æ–‡ä»¶ï¼Œæ›´æ–°å®ƒ
                existing_file_id = existing_files[0]['id']
                existing_file_name = existing_files[0]['name']
                print(f"ğŸ“„ æ‰¾åˆ°ç¾æœ‰æ–‡ä»¶: {existing_file_name} (ID: {existing_file_id})")
                updated_file = service.files().update(
                    fileId=existing_file_id,
                    media_body=media,
                    fields='id,name,webViewLink'
                ).execute()
                print(f"âœ… [Drive] æ›´æ–°ç¾æœ‰æ–‡ä»¶: {updated_file.get('name')} (ID: {existing_file_id})")
                print(f"   ğŸ”— æª¢è¦–é€£çµ: {updated_file.get('webViewLink', 'N/A')}")
                print(f"   ğŸ’¡ å»ºè­°å°‡æ­¤æ–‡ä»¶ ID ({existing_file_id}) æ–°å¢ç‚º GitHub Secret")
                
                # æ¸…ç†è‡¨æ™‚å‰µå»ºçš„ XLSX æ–‡ä»¶ï¼ˆå¦‚æœåŸå§‹æ˜¯ CSVï¼‰
                if upload_file != local_file and upload_file.endswith('.xlsx'):
                    try:
                        os.remove(upload_file)
                        print(f"ğŸ§¹ å·²æ¸…ç†è‡¨æ™‚æ–‡ä»¶: {upload_file}")
                    except:
                        pass
                
                return True
            else:
                # æ²’æœ‰æ‰¾åˆ°ç¾æœ‰æ–‡ä»¶ï¼Œå‰µå»ºæ–°æ–‡ä»¶
                print(f"ğŸ“ æœªæ‰¾åˆ°ç¾æœ‰æ–‡ä»¶ï¼Œå‰µå»ºæ–°æ–‡ä»¶...")
                create_name = search_name if upload_file.endswith('.xlsx') else file_name
                file_metadata = {
                    'name': create_name
                }
                
                # å¦‚æœæŒ‡å®šäº†è³‡æ–™å¤¾ï¼Œè¨­å®šçˆ¶è³‡æ–™å¤¾ï¼›å¦å‰‡å‰µå»ºåœ¨æ ¹ç›®éŒ„
                if folder_id:
                    file_metadata['parents'] = [folder_id]
                    print(f"   ğŸ“ ç›®æ¨™è³‡æ–™å¤¾ ID: {folder_id}")
                else:
                    print(f"   ğŸ“ å‰µå»ºåœ¨æ ¹ç›®éŒ„ï¼ˆèˆ‡å…¶ä»–æ–‡ä»¶åŒè·¯å¾‘ï¼‰")
                
                created_file = service.files().create(
                    body=file_metadata,
                    media_body=media,
                    fields='id,name,webViewLink'
                ).execute()
                print(f"âœ… [Drive] æ–°å¢æ–‡ä»¶: {created_file.get('name')}")
                print(f"   ğŸ“ æ–‡ä»¶ ID: {created_file.get('id')}")
                print(f"   ğŸ”— æª¢è¦–é€£çµ: {created_file.get('webViewLink', 'N/A')}")
                print(f"   ğŸ’¡ å»ºè­°å°‡æ­¤æ–‡ä»¶ ID ({created_file.get('id')}) æ–°å¢ç‚º GitHub Secret")
                
                # æ¸…ç†è‡¨æ™‚å‰µå»ºçš„ XLSX æ–‡ä»¶ï¼ˆå¦‚æœåŸå§‹æ˜¯ CSVï¼‰
                if upload_file != local_file and upload_file.endswith('.xlsx'):
                    try:
                        os.remove(upload_file)
                        print(f"ğŸ§¹ å·²æ¸…ç†è‡¨æ™‚æ–‡ä»¶: {upload_file}")
                    except:
                        pass
                
                return True
                
        except Exception as create_error:
            error_msg = str(create_error)
            print(f"âŒ [Drive] æœç´¢æˆ–å‰µå»ºæ–‡ä»¶å¤±æ•—: {create_error}")
            if '404' in error_msg or 'notFound' in error_msg:
                if folder_id:
                    print(f"   ğŸ’¡ å¦‚æœæ–‡ä»¶åœ¨æ ¹ç›®éŒ„ï¼Œè«‹ä¸è¦è¨­ç½® GOOGLE_DRIVE_FOLDER_ID")
                    print(f"   ğŸ’¡ æˆ–è€…ç›´æ¥è¨­ç½® BEST_STRATEGIES_FANTASY5_FILE_ID æˆ– BEST_STRATEGIES_539_FILE_ID")
            return False
        
        return True

    except json.JSONDecodeError as e:
        print(f"âŒ [Drive] èªè­‰è³‡è¨Šæ ¼å¼éŒ¯èª¤: {e}")
        return False
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ [Drive] ä¸Šå‚³å¤±æ•—: {error_msg}")
        
        # é‡å°å¸¸è¦‹éŒ¯èª¤æä¾›è§£æ±ºæ–¹æ¡ˆ
        if '404' in error_msg or 'notFound' in error_msg:
            print(f"   ğŸ’¡ é€™é€šå¸¸æ˜¯å› ç‚º:")
            print(f"      1. è³‡æ–™å¤¾ ID ä¸æ­£ç¢º")
            print(f"      2. æœå‹™å¸³è™Ÿæ²’æœ‰æ¬Šé™è¨ªå•è©²è³‡æ–™å¤¾")
            print(f"      3. è³‡æ–™å¤¾å·²è¢«åˆªé™¤")
            print(f"   ğŸ’¡ è§£æ±ºæ–¹æ¡ˆ:")
            print(f"      1. ç¢ºèª GOOGLE_DRIVE_FOLDER_ID æ˜¯å¦æ­£ç¢º")
            print(f"      2. åœ¨ Google Drive ä¸­åˆ†äº«è³‡æ–™å¤¾çµ¦æœå‹™å¸³è™Ÿ")
            print(f"      3. ç¢ºä¿æœå‹™å¸³è™Ÿæœ‰ã€Œç·¨è¼¯è€…ã€æ¬Šé™")
        elif '403' in error_msg or 'permission' in error_msg.lower():
            print(f"   ğŸ’¡ æ¬Šé™ä¸è¶³ï¼Œè«‹ç¢ºèªæœå‹™å¸³è™Ÿæœ‰ã€Œç·¨è¼¯è€…ã€æ¬Šé™")
        elif '401' in error_msg or 'unauthorized' in error_msg.lower():
            print(f"   ğŸ’¡ èªè­‰å¤±æ•—ï¼Œè«‹ç¢ºèª GOOGLE_CREDENTIALS æ˜¯å¦æ­£ç¢º")
        
        import traceback
        traceback.print_exc()
        return False

# ==========================================
# ä¸»æµç¨‹
# ==========================================
def process_single(name, input_file, output_file, is_fantasy, file_id=None, folder_id=None, creds=None):
    """è™•ç†å–®ä¸€å½©çƒçš„åˆ†æ"""
    print(f"\nâš¡ åˆ†æ {name} (è½‰æ›æ™‚å€: {is_fantasy})...")
    df = load_data(input_file, is_fantasy)
    if df is None:
        print(f"âŒ æ‰¾ä¸åˆ° {input_file}ï¼Œè·³é")
        return False
        
    # æ—¥æœŸç¯©é¸
    max_date = df['Analysis_Date'].max()
    cutoff_8wk = max_date - pd.Timedelta(weeks=8)
    cutoff_1yr = max_date - pd.Timedelta(weeks=52)
    
    data_by_week = get_data_by_week(df)
    all_weeks = sorted(data_by_week.keys())
    
    weeks_8wk = [w for w in all_weeks if w in get_data_by_week(df[df['Analysis_Date'] >= cutoff_8wk])][1:] # ç•¥éè³‡æ–™ä¸å…¨çš„ç•¶é€±
    weeks_1yr = [w for w in all_weeks if w in get_data_by_week(df[df['Analysis_Date'] >= cutoff_1yr])]
    
    # 1. çŸ­æœŸ (8é€±)
    print("   -> è¨ˆç®—çŸ­æœŸå‹ç‡...")
    df_short = calculate_stats(data_by_week, weeks_8wk, mode="win_rate")
    
    # 2. é•·æœŸ (1å¹´)
    print("   -> è¨ˆç®—é•·æœŸå‹ç‡...")
    df_long = calculate_stats(data_by_week, weeks_1yr, mode="win_rate")
    
    # 3. é€£èŠ
    print("   -> è¨ˆç®—é€£èŠéœ¸ä¸»...")
    df_streak = calculate_stats(data_by_week, all_weeks, mode="streak")
    
    # å½™æ•´
    report = []
    
    # çŸ­æœŸ (é–€æª» 85%)
    s1, s2 = select_best_strategies(df_short, threshold=0.85)
    report.append({"ç­–ç•¥ç¶­åº¦": "çŸ­æœŸçˆ†ç™¼ (è¿‘8é€±)", "ç¬¬ä¸€çµ„": s1, "ç¬¬äºŒçµ„": s2})
    
    # é•·æœŸ (é–€æª» 90%ï¼Œä½æ–¼é¡¯ç¤ºç„¡æ•¸æ“š)
    l1, l2 = select_best_strategies(df_long, threshold=0.90)
    report.append({"ç­–ç•¥ç¶­åº¦": "é•·æœŸç©©å¥ (è¿‘1å¹´)", "ç¬¬ä¸€çµ„": l1, "ç¬¬äºŒçµ„": l2})
    
    # é€£èŠ (è‡³å°‘é€£5é€±)
    st1, st2 = select_best_strategies(df_streak, threshold=5)
    report.append({"ç­–ç•¥ç¶­åº¦": "é€£èŠéœ¸ä¸» (é€£å‹ä¸­)", "ç¬¬ä¸€çµ„": st1, "ç¬¬äºŒçµ„": st2})
    
    # è¼¸å‡º CSV (ç¢ºä¿ä¸€å®šæœƒå‰µå»ºæ–‡ä»¶)
    res_df = pd.DataFrame(report)
    res_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"ğŸ“„ å·²å»ºç«‹: {output_file}")
    
    # é©—è­‰æ–‡ä»¶ç¢ºå¯¦å­˜åœ¨
    if not os.path.exists(output_file):
        print(f"âŒ è­¦å‘Š: {output_file} å‰µå»ºå¤±æ•—")
        return False
    
    # ä¸Šå‚³åˆ° Google Drive
    if creds:
        try:
            upload_to_drive(output_file, file_id=file_id, folder_id=folder_id, creds_json=creds)
            print(f"âœ… {output_file} å·²ä¸Šå‚³åˆ° Google Drive")
        except Exception as e:
            print(f"âš ï¸ ä¸Šå‚³ {output_file} åˆ° Google Drive æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            print(f"   æœ¬åœ°æ–‡ä»¶å·²å‰µå»º: {output_file}")
    else:
        print(f"âš ï¸ æœªè¨­ç½® GOOGLE_CREDENTIALS")
        print(f"   ğŸ“„ æœ¬åœ°æ–‡ä»¶å·²å‰µå»º: {output_file}")
        print(f"   ğŸ’¡ æç¤º: åœ¨ GitHub Actions ä¸­ï¼Œç’°å¢ƒè®Šæ•¸æœƒè‡ªå‹•å¾ Secrets è®€å–")
        print(f"   ğŸ’¡ æœ¬åœ°æ¸¬è©¦æ™‚ï¼Œå¯ä»¥æ‰‹å‹•è¨­ç½®ç’°å¢ƒè®Šæ•¸æˆ–è·³éä¸Šå‚³æ­¥é©Ÿ")
    
    return True

def process_all():
    """è™•ç†æ‰€æœ‰å½©çƒçš„åˆ†æï¼ˆé è¨­è¡Œç‚ºï¼‰"""
    folder_id = os.environ.get('GOOGLE_DRIVE_FOLDER_ID')
    creds = os.environ.get('GOOGLE_CREDENTIALS')
    
    file_id_539 = os.environ.get('BEST_STRATEGIES_539_FILE_ID')
    file_id_fantasy = os.environ.get('BEST_STRATEGIES_FANTASY5_FILE_ID')

    tasks = [
        ("539", FILE_539, OUTPUT_539, False, file_id_539),
        ("å¤©å¤©æ¨‚", FILE_FANTASY, OUTPUT_FANTASY, True, file_id_fantasy)
    ]

    for name, input_file, output_file, is_fantasy, file_id in tasks:
        process_single(name, input_file, output_file, is_fantasy, file_id=file_id, folder_id=folder_id, creds=creds)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='åˆ†æå½©çƒç­–ç•¥')
    parser.add_argument('--type', type=str, choices=['539', 'fantasy5', 'all'], 
                       default='all', help='æŒ‡å®šè¦åˆ†æçš„å½©çƒé¡å‹: 539, fantasy5, æˆ– all (é è¨­)')
    
    args = parser.parse_args()
    
    folder_id = os.environ.get('GOOGLE_DRIVE_FOLDER_ID')
    creds = os.environ.get('GOOGLE_CREDENTIALS')
    file_id_539 = os.environ.get('BEST_STRATEGIES_539_FILE_ID')
    file_id_fantasy = os.environ.get('BEST_STRATEGIES_FANTASY5_FILE_ID')
    
    if args.type == '539':
        print("ğŸ¯ åƒ…åˆ†æ 539...")
        process_single("539", FILE_539, OUTPUT_539, False, file_id=file_id_539, folder_id=folder_id, creds=creds)
    elif args.type == 'fantasy5':
        print("ğŸ¯ åƒ…åˆ†æå¤©å¤©æ¨‚...")
        process_single("å¤©å¤©æ¨‚", FILE_FANTASY, OUTPUT_FANTASY, True, file_id=file_id_fantasy, folder_id=folder_id, creds=creds)
    else:
        print("ğŸ¯ åˆ†ææ‰€æœ‰å½©çƒ...")
        process_all()